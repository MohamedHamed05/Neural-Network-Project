{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T23:33:56.259794Z",
     "iopub.status.busy": "2025-05-12T23:33:56.259239Z",
     "iopub.status.idle": "2025-05-12T23:34:00.719947Z",
     "shell.execute_reply": "2025-05-12T23:34:00.719221Z",
     "shell.execute_reply.started": "2025-05-12T23:33:56.259771Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in /usr/local/lib/python3.11/dist-packages (2.14.1)\n",
      "Collecting contractions\n",
      "  Downloading contractions-0.1.73-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting textsearch>=0.0.21 (from contractions)\n",
      "  Downloading textsearch-0.0.24-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
      "  Downloading anyascii-0.3.2-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
      "  Downloading pyahocorasick-2.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
      "Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyahocorasick-2.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (118 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.3/118.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
      "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.1.0 textsearch-0.0.24\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T23:34:02.535686Z",
     "iopub.status.busy": "2025-05-12T23:34:02.535390Z",
     "iopub.status.idle": "2025-05-12T23:34:15.384308Z",
     "shell.execute_reply": "2025-05-12T23:34:15.383539Z",
     "shell.execute_reply.started": "2025-05-12T23:34:02.535661Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 23:34:04.522186: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747092844.722241      32 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747092844.777411      32 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import emoji\n",
    "import contractions\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import zipfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer , TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import f1_score , classification_report , confusion_matrix\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Embedding, SpatialDropout1D, Conv1D, MaxPooling1D, Bidirectional, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.losses import BinaryFocalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Precision , Recall , F1Score\n",
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T16:24:47.337433Z",
     "iopub.status.busy": "2025-05-11T16:24:47.337173Z",
     "iopub.status.idle": "2025-05-11T16:24:47.346581Z",
     "shell.execute_reply": "2025-05-11T16:24:47.345961Z",
     "shell.execute_reply.started": "2025-05-11T16:24:47.337412Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!wget --no-check-certificate http://nlp.stanford.edu/data/glove.6B.zip -O /kaggle/working/glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T23:34:15.386035Z",
     "iopub.status.busy": "2025-05-12T23:34:15.385451Z",
     "iopub.status.idle": "2025-05-12T23:34:15.943473Z",
     "shell.execute_reply": "2025-05-12T23:34:15.942748Z",
     "shell.execute_reply.started": "2025-05-12T23:34:15.386009Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T16:24:47.348198Z",
     "iopub.status.busy": "2025-05-11T16:24:47.347786Z",
     "iopub.status.idle": "2025-05-11T16:24:47.356965Z",
     "shell.execute_reply": "2025-05-11T16:24:47.356346Z",
     "shell.execute_reply.started": "2025-05-11T16:24:47.348182Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Extract the GloVe files\n",
    "with zipfile.ZipFile('/kaggle/working/glove.6B.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('/kaggle/working/glove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T23:35:16.573671Z",
     "iopub.status.busy": "2025-05-12T23:35:16.573367Z",
     "iopub.status.idle": "2025-05-12T23:35:16.587451Z",
     "shell.execute_reply": "2025-05-12T23:35:16.586769Z",
     "shell.execute_reply.started": "2025-05-12T23:35:16.573650Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "slang_dict = {\n",
    "    \"$\" : \" dollar \",\n",
    "    \"€\" : \" euro \",\n",
    "    \"4ao\" : \"for adults only\",\n",
    "    \"a.m\" : \"before midday\",\n",
    "    \"a3\" : \"anytime anywhere anyplace\",\n",
    "    \"aamof\" : \"as a matter of fact\",\n",
    "    \"acct\" : \"account\",\n",
    "    \"adih\" : \"another day in hell\",\n",
    "    \"afaic\" : \"as far as i am concerned\",\n",
    "    \"afaict\" : \"as far as i can tell\",\n",
    "    \"afaik\" : \"as far as i know\",\n",
    "    \"afair\" : \"as far as i remember\",\n",
    "    \"afk\" : \"away from keyboard\",\n",
    "    \"app\" : \"application\",\n",
    "    \"approx\" : \"approximately\",\n",
    "    \"apps\" : \"applications\",\n",
    "    \"asap\" : \"as soon as possible\",\n",
    "    \"asl\" : \"age, sex, location\",\n",
    "    \"atk\" : \"at the keyboard\",\n",
    "    \"ave.\" : \"avenue\",\n",
    "    \"aymm\" : \"are you my mother\",\n",
    "    \"ayor\" : \"at your own risk\",\n",
    "    \"b&b\" : \"bed and breakfast\",\n",
    "    \"b+b\" : \"bed and breakfast\",\n",
    "    \"b.c\" : \"before christ\",\n",
    "    \"b2b\" : \"business to business\",\n",
    "    \"b2c\" : \"business to customer\",\n",
    "    \"b4\" : \"before\",\n",
    "    \"b4n\" : \"bye for now\",\n",
    "    \"b@u\" : \"back at you\",\n",
    "    \"bae\" : \"before anyone else\",\n",
    "    \"bak\" : \"back at keyboard\",\n",
    "    \"bbbg\" : \"bye bye be good\",\n",
    "    \"bbc\" : \"british broadcasting corporation\",\n",
    "    \"bbias\" : \"be back in a second\",\n",
    "    \"bbl\" : \"be back later\",\n",
    "    \"bbs\" : \"be back soon\",\n",
    "    \"be4\" : \"before\",\n",
    "    \"bfn\" : \"bye for now\",\n",
    "    \"blvd\" : \"boulevard\",\n",
    "    \"bout\" : \"about\",\n",
    "    \"brb\" : \"be right back\",\n",
    "    \"bros\" : \"brothers\",\n",
    "    \"brt\" : \"be right there\",\n",
    "    \"bsaaw\" : \"big smile and a wink\",\n",
    "    \"btw\" : \"by the way\",\n",
    "    \"bwl\" : \"bursting with laughter\",\n",
    "    \"c/o\" : \"care of\",\n",
    "    \"cet\" : \"central european time\",\n",
    "    \"cf\" : \"compare\",\n",
    "    \"cia\" : \"central intelligence agency\",\n",
    "    \"csl\" : \"can not stop laughing\",\n",
    "    \"cu\" : \"see you\",\n",
    "    \"cul8r\" : \"see you later\",\n",
    "    \"cv\" : \"curriculum vitae\",\n",
    "    \"cwot\" : \"complete waste of time\",\n",
    "    \"cya\" : \"see you\",\n",
    "    \"cyt\" : \"see you tomorrow\",\n",
    "    \"dae\" : \"does anyone else\",\n",
    "    \"dbmib\" : \"do not bother me i am busy\",\n",
    "    \"diy\" : \"do it yourself\",\n",
    "    \"dm\" : \"direct message\",\n",
    "    \"dwh\" : \"during work hours\",\n",
    "    \"e123\" : \"easy as one two three\",\n",
    "    \"eet\" : \"eastern european time\",\n",
    "    \"eg\" : \"example\",\n",
    "    \"embm\" : \"early morning business meeting\",\n",
    "    \"encl\" : \"enclosed\",\n",
    "    \"encl.\" : \"enclosed\",\n",
    "    \"etc\" : \"and so on\",\n",
    "    \"faq\" : \"frequently asked questions\",\n",
    "    \"fawc\" : \"for anyone who cares\",\n",
    "    \"fb\" : \"facebook\",\n",
    "    \"fc\" : \"fingers crossed\",\n",
    "    \"fig\" : \"figure\",\n",
    "    \"fimh\" : \"forever in my heart\",\n",
    "    \"ft.\" : \"feet\",\n",
    "    \"ft\" : \"featuring\",\n",
    "    \"ftl\" : \"for the loss\",\n",
    "    \"ftw\" : \"for the win\",\n",
    "    \"fwiw\" : \"for what it is worth\",\n",
    "    \"fyi\" : \"for your information\",\n",
    "    \"g9\" : \"genius\",\n",
    "    \"gahoy\" : \"get a hold of yourself\",\n",
    "    \"gal\" : \"get a life\",\n",
    "    \"gcse\" : \"general certificate of secondary education\",\n",
    "    \"gfn\" : \"gone for now\",\n",
    "    \"gg\" : \"good game\",\n",
    "    \"gl\" : \"good luck\",\n",
    "    \"glhf\" : \"good luck have fun\",\n",
    "    \"gmt\" : \"greenwich mean time\",\n",
    "    \"gmta\" : \"great minds think alike\",\n",
    "    \"gn\" : \"good night\",\n",
    "    \"g.o.a.t\" : \"greatest of all time\",\n",
    "    \"goat\" : \"greatest of all time\",\n",
    "    \"goi\" : \"get over it\",\n",
    "    \"gps\" : \"global positioning system\",\n",
    "    \"gr8\" : \"great\",\n",
    "    \"gratz\" : \"congratulations\",\n",
    "    \"gyal\" : \"girl\",\n",
    "    \"h&c\" : \"hot and cold\",\n",
    "    \"hp\" : \"horsepower\",\n",
    "    \"hr\" : \"hour\",\n",
    "    \"hrh\" : \"his royal highness\",\n",
    "    \"ht\" : \"height\",\n",
    "    \"ibrb\" : \"i will be right back\",\n",
    "    \"im\" : \"i am\",\n",
    "    \"ic\" : \"i see\",\n",
    "    \"icq\" : \"i seek you\",\n",
    "    \"icymi\" : \"in case you missed it\",\n",
    "    \"idc\" : \"i do not care\",\n",
    "    \"idgadf\" : \"i do not give a damn fuck\",\n",
    "    \"idgaf\" : \"i do not give a fuck\",\n",
    "    \"idk\" : \"i do not know\",\n",
    "    \"ie\" : \"that is\",\n",
    "    \"i.e\" : \"that is\",\n",
    "    \"ifyp\" : \"i feel your pain\",\n",
    "    \"IG\" : \"instagram\",\n",
    "    \"iirc\" : \"if i remember correctly\",\n",
    "    \"ilu\" : \"i love you\",\n",
    "    \"ily\" : \"i love you\",\n",
    "    \"imho\" : \"in my humble opinion\",\n",
    "    \"imo\" : \"in my opinion\",\n",
    "    \"imu\" : \"i miss you\",\n",
    "    \"iow\" : \"in other words\",\n",
    "    \"irl\" : \"in real life\",\n",
    "    \"j4f\" : \"just for fun\",\n",
    "    \"jic\" : \"just in case\",\n",
    "    \"jk\" : \"just kidding\",\n",
    "    \"jsyk\" : \"just so you know\",\n",
    "    \"l8r\" : \"later\",\n",
    "    \"lb\" : \"pound\",\n",
    "    \"lbs\" : \"pounds\",\n",
    "    \"ldr\" : \"long distance relationship\",\n",
    "    \"lmao\" : \"laugh my ass off\",\n",
    "    \"lmfao\" : \"laugh my fucking ass off\",\n",
    "    \"lol\" : \"laughing out loud\",\n",
    "    \"ltd\" : \"limited\",\n",
    "    \"ltns\" : \"long time no see\",\n",
    "    \"m8\" : \"mate\",\n",
    "    \"mf\" : \"motherfucker\",\n",
    "    \"mfs\" : \"motherfuckers\",\n",
    "    \"mfw\" : \"my face when\",\n",
    "    \"mofo\" : \"motherfucker\",\n",
    "    \"mph\" : \"miles per hour\",\n",
    "    \"mr\" : \"mister\",\n",
    "    \"mrw\" : \"my reaction when\",\n",
    "    \"ms\" : \"miss\",\n",
    "    \"mte\" : \"my thoughts exactly\",\n",
    "    \"nagi\" : \"not a good idea\",\n",
    "    \"nbc\" : \"national broadcasting company\",\n",
    "    \"nbd\" : \"not big deal\",\n",
    "    \"nfs\" : \"not for sale\",\n",
    "    \"ngl\" : \"not going to lie\",\n",
    "    \"nhs\" : \"national health service\",\n",
    "    \"nrn\" : \"no reply necessary\",\n",
    "    \"nsfl\" : \"not safe for life\",\n",
    "    \"nsfw\" : \"not safe for work\",\n",
    "    \"nth\" : \"nice to have\",\n",
    "    \"nvr\" : \"never\",\n",
    "    \"nyc\" : \"new york city\",\n",
    "    \"oc\" : \"original content\",\n",
    "    \"og\" : \"original\",\n",
    "    \"ohp\" : \"overhead projector\",\n",
    "    \"oic\" : \"oh i see\",\n",
    "    \"omdb\" : \"over my dead body\",\n",
    "    \"omg\" : \"oh my god\",\n",
    "    \"omw\" : \"on my way\",\n",
    "    \"p.a\" : \"per annum\",\n",
    "    \"p.m\" : \"after midday\",\n",
    "    \"pm\" : \"prime minister\",\n",
    "    \"poc\" : \"people of color\",\n",
    "    \"pov\" : \"point of view\",\n",
    "    \"pp\" : \"pages\",\n",
    "    \"ppl\" : \"people\",\n",
    "    \"prw\" : \"parents are watching\",\n",
    "    \"ps\" : \"postscript\",\n",
    "    \"pt\" : \"point\",\n",
    "    \"ptb\" : \"please text back\",\n",
    "    \"pto\" : \"please turn over\",\n",
    "    \"qpsa\" : \"what happens\", #\"que pasa\",\n",
    "    \"ratchet\" : \"rude\",\n",
    "    \"rbtl\" : \"read between the lines\",\n",
    "    \"rlrt\" : \"real life retweet\",\n",
    "    \"rofl\" : \"rolling on the floor laughing\",\n",
    "    \"roflol\" : \"rolling on the floor laughing out loud\",\n",
    "    \"rotflmao\" : \"rolling on the floor laughing my ass off\",\n",
    "    \"rt\" : \"retweet\",\n",
    "    \"ruok\" : \"are you ok\",\n",
    "    \"sfw\" : \"safe for work\",\n",
    "    \"sk8\" : \"skate\",\n",
    "    \"smh\" : \"shake my head\",\n",
    "    \"sq\" : \"square\",\n",
    "    \"srsly\" : \"seriously\",\n",
    "    \"ssdd\" : \"same stuff different day\",\n",
    "    \"tbh\" : \"to be honest\",\n",
    "    \"tbs\" : \"tablespooful\",\n",
    "    \"tbsp\" : \"tablespooful\",\n",
    "    \"tfw\" : \"that feeling when\",\n",
    "    \"thks\" : \"thank you\",\n",
    "    \"tho\" : \"though\",\n",
    "    \"thx\" : \"thank you\",\n",
    "    \"tia\" : \"thanks in advance\",\n",
    "    \"til\" : \"today i learned\",\n",
    "    \"tl;dr\" : \"too long i did not read\",\n",
    "    \"tldr\" : \"too long i did not read\",\n",
    "    \"tmb\" : \"tweet me back\",\n",
    "    \"tntl\" : \"trying not to laugh\",\n",
    "    \"ttyl\" : \"talk to you later\",\n",
    "    \"u\" : \"you\",\n",
    "    \"u2\" : \"you too\",\n",
    "    \"u4e\" : \"yours for ever\",\n",
    "    \"utc\" : \"coordinated universal time\",\n",
    "    \"w/\" : \"with\",\n",
    "    \"w/o\" : \"without\",\n",
    "    \"w8\" : \"wait\",\n",
    "    \"wassup\" : \"what is up\",\n",
    "    \"wb\" : \"welcome back\",\n",
    "    \"wtf\" : \"what the fuck\",\n",
    "    \"wtg\" : \"way to go\",\n",
    "    \"wtpa\" : \"where the party at\",\n",
    "    \"wuf\" : \"where are you from\",\n",
    "    \"wuzup\" : \"what is up\",\n",
    "    \"wywh\" : \"wish you were here\",\n",
    "    \"yd\" : \"yard\",\n",
    "    \"ygtr\" : \"you got that right\",\n",
    "    \"ynk\" : \"you never know\",\n",
    "    \"zzz\" : \"sleeping bored and tired\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T23:35:22.546309Z",
     "iopub.status.busy": "2025-05-12T23:35:22.546045Z",
     "iopub.status.idle": "2025-05-12T23:35:22.552574Z",
     "shell.execute_reply": "2025-05-12T23:35:22.551807Z",
     "shell.execute_reply.started": "2025-05-12T23:35:22.546289Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    if pd.isna(text): \n",
    "        return \"\"\n",
    "\n",
    "    text = text.lower() #convert to lowercase\n",
    "    text = emoji.demojize(text) #convert emojis to alternative text\n",
    "    text = text.replace(\":\", \"\").replace(\"_\", \" \") #remove colons and underscores\n",
    "    text = contractions.fix(text) #expand contractions EX: \"don't\" to \"do not\"\n",
    "    \n",
    "    #we split the text to check for slang words and replace them\n",
    "    words = text.split() \n",
    "    processed_words = []\n",
    "    for word in words:\n",
    "        word_cleaned = word.strip(string.punctuation)\n",
    "        if word_cleaned.lower() in slang_dict:\n",
    "            processed_words.append(slang_dict[word_cleaned.lower()])\n",
    "        else:\n",
    "            processed_words.append(word)\n",
    "        text = \" \".join(processed_words)\n",
    "\n",
    "        text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text) #remove URLS\n",
    "        text = re.sub(r'[^\\w\\s\\.\\!\\?]', ' ', text) #remove special characters\n",
    "        text = re.sub(r'\\s+', ' ', text).strip() #remove extra spaces\n",
    "\n",
    "        tokens = word_tokenize(text) #tokenizing the text\n",
    "\n",
    "        stop_words = set(stopwords.words('english')) #remove stop words\n",
    "        tokens = [token for token in tokens if token not in stop_words and len(token) > 1]\n",
    "\n",
    "        lemmatizer = WordNetLemmatizer() #lemmatizing the tokens\n",
    "        tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T23:35:29.671847Z",
     "iopub.status.busy": "2025-05-12T23:35:29.671094Z",
     "iopub.status.idle": "2025-05-12T23:35:30.585406Z",
     "shell.execute_reply": "2025-05-12T23:35:30.584805Z",
     "shell.execute_reply.started": "2025-05-12T23:35:29.671794Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>attraction</th>\n",
       "      <th>rate</th>\n",
       "      <th>date</th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>processed_review</th>\n",
       "      <th>review_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>year</th>\n",
       "      <th>...</th>\n",
       "      <th>negation_count</th>\n",
       "      <th>negation_ratio</th>\n",
       "      <th>has_mixed_sentiment</th>\n",
       "      <th>sentiment_binary</th>\n",
       "      <th>sentiment_score_binary</th>\n",
       "      <th>sentiment_vader</th>\n",
       "      <th>sentiment_score_vader</th>\n",
       "      <th>sentiment_binary_distil</th>\n",
       "      <th>sentiment_score_binary_distil</th>\n",
       "      <th>sentiment_ensemble</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Pyramids of Giza</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2025-02-17</td>\n",
       "      <td>Well worth going to visit. If you are getting ...</td>\n",
       "      <td>1</td>\n",
       "      <td>well worth going visit getting tour fantastic ...</td>\n",
       "      <td>255</td>\n",
       "      <td>49</td>\n",
       "      <td>2025</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.998857</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.8357</td>\n",
       "      <td>non_positive</td>\n",
       "      <td>0.671923</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Pyramids of Giza</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2025-02-15</td>\n",
       "      <td>The splendor of the pyramidsThe Seven Wonders ...</td>\n",
       "      <td>1</td>\n",
       "      <td>splendor pyramidsthe seven wonder world seen p...</td>\n",
       "      <td>137</td>\n",
       "      <td>23</td>\n",
       "      <td>2025</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.998818</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.7184</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.999620</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Pyramids of Giza</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2025-02-13</td>\n",
       "      <td>The pyramids are among the most beautiful arch...</td>\n",
       "      <td>1</td>\n",
       "      <td>pyramid among beautiful archaeological site wo...</td>\n",
       "      <td>574</td>\n",
       "      <td>90</td>\n",
       "      <td>2025</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.998801</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.999869</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Pyramids of Giza</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2025-02-09</td>\n",
       "      <td>yes it crowded, yes there is some tourist trap...</td>\n",
       "      <td>1</td>\n",
       "      <td>yes crowded yes tourist trap yes queue frustra...</td>\n",
       "      <td>310</td>\n",
       "      <td>57</td>\n",
       "      <td>2025</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.998868</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.8020</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.990586</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Pyramids of Giza</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2025-02-07</td>\n",
       "      <td>History &amp; Mystery of The Pyramids, What a Day,...</td>\n",
       "      <td>1</td>\n",
       "      <td>history mystery pyramid day hit visit land leg...</td>\n",
       "      <td>131</td>\n",
       "      <td>23</td>\n",
       "      <td>2025</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>True</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.998885</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.915993</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        attraction  rate        date  \\\n",
       "0           0  Pyramids of Giza   5.0  2025-02-17   \n",
       "1           1  Pyramids of Giza   5.0  2025-02-15   \n",
       "2           2  Pyramids of Giza   5.0  2025-02-13   \n",
       "3           3  Pyramids of Giza   5.0  2025-02-09   \n",
       "4           4  Pyramids of Giza   5.0  2025-02-07   \n",
       "\n",
       "                                              review  sentiment  \\\n",
       "0  Well worth going to visit. If you are getting ...          1   \n",
       "1  The splendor of the pyramidsThe Seven Wonders ...          1   \n",
       "2  The pyramids are among the most beautiful arch...          1   \n",
       "3  yes it crowded, yes there is some tourist trap...          1   \n",
       "4  History & Mystery of The Pyramids, What a Day,...          1   \n",
       "\n",
       "                                    processed_review  review_length  \\\n",
       "0  well worth going visit getting tour fantastic ...            255   \n",
       "1  splendor pyramidsthe seven wonder world seen p...            137   \n",
       "2  pyramid among beautiful archaeological site wo...            574   \n",
       "3  yes crowded yes tourist trap yes queue frustra...            310   \n",
       "4  history mystery pyramid day hit visit land leg...            131   \n",
       "\n",
       "   word_count  year  ...  negation_count  negation_ratio  has_mixed_sentiment  \\\n",
       "0          49  2025  ...               0        0.000000                 True   \n",
       "1          23  2025  ...               0        0.000000                False   \n",
       "2          90  2025  ...               0        0.000000                False   \n",
       "3          57  2025  ...               0        0.000000                False   \n",
       "4          23  2025  ...               2        0.086957                 True   \n",
       "\n",
       "   sentiment_binary  sentiment_score_binary  sentiment_vader  \\\n",
       "0          positive                0.998857         positive   \n",
       "1          positive                0.998818         positive   \n",
       "2          positive                0.998801         positive   \n",
       "3          positive                0.998868         positive   \n",
       "4          positive                0.998885         positive   \n",
       "\n",
       "   sentiment_score_vader sentiment_binary_distil  \\\n",
       "0                 0.8357            non_positive   \n",
       "1                 0.7184                positive   \n",
       "2                 0.9524                positive   \n",
       "3                 0.8020                positive   \n",
       "4                 0.4667                positive   \n",
       "\n",
       "   sentiment_score_binary_distil sentiment_ensemble  \n",
       "0                       0.671923           positive  \n",
       "1                       0.999620           positive  \n",
       "2                       0.999869           positive  \n",
       "3                       0.990586           positive  \n",
       "4                       0.915993           positive  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/kaggle/input/tourismmm/labeled_tourism_reviews_binary (1).csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing the Dataset\n",
    "* we choose from every attraction site a smple of positive reviews \n",
    "* if this attraction site has more than 200 reviews we choose random from them \n",
    "* if this sttraction site has less than 200 reviews we take them all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T23:35:32.226277Z",
     "iopub.status.busy": "2025-05-12T23:35:32.226023Z",
     "iopub.status.idle": "2025-05-12T23:35:32.513833Z",
     "shell.execute_reply": "2025-05-12T23:35:32.513019Z",
     "shell.execute_reply.started": "2025-05-12T23:35:32.226259Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "new_df = df[df['sentiment_ensemble'] == 'non_positive']\n",
    "for i in df['attraction'].unique():\n",
    "    tmp = df[(df['attraction'] == i) & (df['sentiment_ensemble'] == 'positive')]\n",
    "    if tmp.shape[0] > 200:\n",
    "        tmp = tmp.sample(200 , random_state = 42)\n",
    "    new_df = pd.concat([new_df , tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T23:35:45.758584Z",
     "iopub.status.busy": "2025-05-12T23:35:45.758129Z",
     "iopub.status.idle": "2025-05-12T23:43:16.232165Z",
     "shell.execute_reply": "2025-05-12T23:43:16.231563Z",
     "shell.execute_reply.started": "2025-05-12T23:35:45.758560Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X = new_df['review'].apply(lambda x : preprocess_text(x))\n",
    "y = new_df['sentiment_ensemble'].map({'positive' : 1 , 'non_positive' : 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T00:11:53.794110Z",
     "iopub.status.busy": "2025-05-13T00:11:53.793519Z",
     "iopub.status.idle": "2025-05-13T00:11:53.804022Z",
     "shell.execute_reply": "2025-05-13T00:11:53.803382Z",
     "shell.execute_reply.started": "2025-05-13T00:11:53.794084Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_data , test_data , train_labels , test_labels = train_test_split(X , y  , test_size = 0.1 , random_state = 42 , stratify = y , shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T00:11:59.190053Z",
     "iopub.status.busy": "2025-05-13T00:11:59.189457Z",
     "iopub.status.idle": "2025-05-13T00:11:59.193338Z",
     "shell.execute_reply": "2025-05-13T00:11:59.192547Z",
     "shell.execute_reply.started": "2025-05-13T00:11:59.190030Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# converting to numpy arrays\n",
    "train_labels = train_labels.to_numpy()\n",
    "test_labels = test_labels.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T00:12:00.563947Z",
     "iopub.status.busy": "2025-05-13T00:12:00.563650Z",
     "iopub.status.idle": "2025-05-13T00:12:01.752281Z",
     "shell.execute_reply": "2025-05-13T00:12:01.751727Z",
     "shell.execute_reply.started": "2025-05-13T00:12:00.563925Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# we extract the most top 10000 frequent words from the reviews\n",
    "# but we do not use the words that appear in more than 90% of the reviews\n",
    "cv = CountVectorizer(ngram_range = (1 , 2) , max_df = 0.9 , max_features=10000)\n",
    "cv_train_data = cv.fit_transform(train_data)\n",
    "cv_test_data = cv.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T00:12:02.089798Z",
     "iopub.status.busy": "2025-05-13T00:12:02.089533Z",
     "iopub.status.idle": "2025-05-13T00:12:02.094621Z",
     "shell.execute_reply": "2025-05-13T00:12:02.093964Z",
     "shell.execute_reply.started": "2025-05-13T00:12:02.089777Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10517,)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T00:12:03.134052Z",
     "iopub.status.busy": "2025-05-13T00:12:03.133429Z",
     "iopub.status.idle": "2025-05-13T00:12:03.138959Z",
     "shell.execute_reply": "2025-05-13T00:12:03.138276Z",
     "shell.execute_reply.started": "2025-05-13T00:12:03.134023Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1169,)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T00:12:15.076960Z",
     "iopub.status.busy": "2025-05-13T00:12:15.076687Z",
     "iopub.status.idle": "2025-05-13T00:12:16.301733Z",
     "shell.execute_reply": "2025-05-13T00:12:16.301189Z",
     "shell.execute_reply.started": "2025-05-13T00:12:15.076936Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "td_idf = TfidfVectorizer(ngram_range = (1 , 2) , max_df = 0.9 , max_features=10000)\n",
    "td_train_data = td_idf.fit_transform(train_data)\n",
    "td_test_data = td_idf.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T16:24:48.257821Z",
     "iopub.status.busy": "2025-05-11T16:24:48.257588Z",
     "iopub.status.idle": "2025-05-11T16:24:56.183394Z",
     "shell.execute_reply": "2025-05-11T16:24:56.182747Z",
     "shell.execute_reply.started": "2025-05-11T16:24:48.257805Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# Load GloVe Word Embeddings\n",
    "# Each line in the glove file is like: king 0.123 0.232 ... 0.543   (100 values)\n",
    "# then we build a Python dictionary embeddings_index that maps each word to its 100-dimensional vector.\n",
    "# it will look like this : embeddings_index['king'] = [0.123, 0.232, ..., 0.543]\n",
    "\n",
    "embeddings_index = {} \n",
    "glove_file = '/kaggle/working/glove/glove.6B.100d.txt'  # Using 100-dimensional embeddings\n",
    "with open(glove_file, encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "print(f'Found {len(embeddings_index)} word vectors.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T16:24:56.186166Z",
     "iopub.status.busy": "2025-05-11T16:24:56.185960Z",
     "iopub.status.idle": "2025-05-11T16:24:56.956599Z",
     "shell.execute_reply": "2025-05-11T16:24:56.956025Z",
     "shell.execute_reply.started": "2025-05-11T16:24:56.186149Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#We Created a Tokenizer that will keep the top 10,000 most frequent words.\n",
    "#oov_token='<OOV>' is a special token used to handle out-of-vocabulary words.\n",
    "#It builds word_index: a dictionary that maps each word to a unique integer ID.\n",
    "#Converts each review in train_data and test_data from text to a list of token IDs.\n",
    "\n",
    "vocab_size = 10000\n",
    "tokenizer = Tokenizer(num_words = vocab_size , oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(train_data)\n",
    "word_index = tokenizer.word_index\n",
    "train_data = tokenizer.texts_to_sequences(train_data)\n",
    "test_data = tokenizer.texts_to_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T16:24:56.957380Z",
     "iopub.status.busy": "2025-05-11T16:24:56.957162Z",
     "iopub.status.idle": "2025-05-11T16:24:57.021095Z",
     "shell.execute_reply": "2025-05-11T16:24:57.020608Z",
     "shell.execute_reply.started": "2025-05-11T16:24:56.957362Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# padding all the reviews to the same length 384\n",
    "maxlen = 384\n",
    "train_data = pad_sequences(train_data, maxlen=maxlen, padding='post', truncating='post') #padding = post means we add zeros at the end of the reviews shorter than 384\n",
    "test_data = pad_sequences(test_data, maxlen=maxlen, padding='post', truncating='post') #truncating  = post means we remove the end of the reviews longer than 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T16:24:57.021984Z",
     "iopub.status.busy": "2025-05-11T16:24:57.021784Z",
     "iopub.status.idle": "2025-05-11T16:24:57.046219Z",
     "shell.execute_reply": "2025-05-11T16:24:57.045755Z",
     "shell.execute_reply.started": "2025-05-11T16:24:57.021968Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#we Create a matrix of shape (vocab_size, embedding_dim) to feed into the model’s Embedding layer.\n",
    "#For each word in the tokenizer’s vocabulary (up to 10,000), it looks up its GloVe vector and adds it to the matrix.\n",
    "#Words not found in GloVe will have zero vectors.\n",
    "#we use all of this to load the pretrained embeddings into the Embedding layer of the model instead of training them from scratch\n",
    "\n",
    "embedding_dim = 100  # Matches glove.6B.100d.txt\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if i < vocab_size:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T16:24:57.047096Z",
     "iopub.status.busy": "2025-05-11T16:24:57.046903Z",
     "iopub.status.idle": "2025-05-11T16:24:57.054014Z",
     "shell.execute_reply": "2025-05-11T16:24:57.053358Z",
     "shell.execute_reply.started": "2025-05-11T16:24:57.047081Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#This class monitors the F1 score (based on precision and recall) on the validation set after each epoch,\n",
    "#and it stops training early if the F1 score doesn't improve after a number of consecutive epochs (patience).\n",
    "# it inherits from the Callback class, which is a base class for Keras callbacks.\n",
    "# it allows you to create custom behaviors during training using callbacks it hooks into the training process using the methods on_epoch_end and on_train_end\n",
    "class EarlyStoppingF1(Callback): \n",
    "    def __init__(self, patience=0, mode='max', restore_best_weights=False):\n",
    "        super(EarlyStoppingF1, self).__init__()\n",
    "        self.patience = patience\n",
    "        self.mode = mode\n",
    "        self.restore_best_weights = restore_best_weights\n",
    "        self.best_weights = None\n",
    "        if mode == 'min':\n",
    "            self.monitor_op = np.less\n",
    "            self.best = np.inf\n",
    "        elif mode == 'max':\n",
    "            self.monitor_op = np.greater\n",
    "            self.best = -np.inf\n",
    "        else:\n",
    "            raise ValueError('Invalid mode')\n",
    "        self.wait = 0\n",
    "        self.stopped_epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_precision = logs.get('val_precision')\n",
    "        val_recall = logs.get('val_recall')\n",
    "        if val_precision is None or val_recall is None:\n",
    "            raise ValueError('Validation precision or recall not found in logs')\n",
    "        # Compute F1 score, avoiding division by zero\n",
    "        if val_precision + val_recall > 0:\n",
    "            val_f1 = 2 * (val_precision * val_recall) / (val_precision + val_recall)\n",
    "        else:\n",
    "            val_f1 = 0\n",
    "        # Check if current F1 score improves over the best\n",
    "        if self.monitor_op(val_f1, self.best):\n",
    "            self.best = val_f1\n",
    "            self.wait = 0\n",
    "            if self.restore_best_weights:\n",
    "                self.best_weights = self.model.get_weights()\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                self.stopped_epoch = epoch\n",
    "                self.model.stop_training = True\n",
    "                if self.restore_best_weights and self.best_weights is not None:\n",
    "                    self.model.set_weights(self.best_weights)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.stopped_epoch > 0:\n",
    "            print(f'Epoch {self.stopped_epoch + 1}: early stopping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T16:24:57.055069Z",
     "iopub.status.busy": "2025-05-11T16:24:57.054824Z",
     "iopub.status.idle": "2025-05-11T16:24:57.067525Z",
     "shell.execute_reply": "2025-05-11T16:24:57.066815Z",
     "shell.execute_reply.started": "2025-05-11T16:24:57.055052Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# we use bidirectional LTSM to process the input in both directions (forward and backward)\n",
    "# forward from start to end.\n",
    "# backward from end to start. \n",
    "#Ex : \"This place is not bad\" starting from \"This\" and starting from \"bad\" the model realize that the word \"not\" affects the meaning of \"bad\"\n",
    "def bilstm():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=100, input_length=maxlen, mask_zero=True))#embedding without the pre-trained weights (Glove)\n",
    "    model.add(SpatialDropout1D(0.4))#Randomly drops 40% of the entire embedding dimensions \n",
    "    model.add(Bidirectional(LSTM(64)))\n",
    "    model.add(Dropout(0.4)) # randomly sets 40% of the neurons to 0\n",
    "    model.add(Dense(64, activation='relu'))#Dense layer for feature abstraction\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid')) #output layer with sigmoid activation function\n",
    "    \n",
    "    model.compile(\n",
    "        loss=BinaryFocalCrossentropy(apply_class_balancing=True),#helps to handle class imbalance\n",
    "        optimizer=Adam(learning_rate=0.0001),\n",
    "        metrics=['accuracy', Precision(name='precision'), Recall(name='recall')]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T16:24:57.069048Z",
     "iopub.status.busy": "2025-05-11T16:24:57.068376Z",
     "iopub.status.idle": "2025-05-11T16:24:57.080662Z",
     "shell.execute_reply": "2025-05-11T16:24:57.079990Z",
     "shell.execute_reply.started": "2025-05-11T16:24:57.069025Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# the same as the last model but with pre-trained embedding weights (Glove)\n",
    "def pre_bilstm():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=maxlen, weights=[embedding_matrix], trainable=False,mask_zero=True))\n",
    "    model.add(SpatialDropout1D(0.4))\n",
    "    model.add(Bidirectional(LSTM(64)))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(\n",
    "        loss=BinaryFocalCrossentropy(apply_class_balancing=True),\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        metrics=['accuracy', Precision(name='precision'), Recall(name='recall')]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T16:24:57.081905Z",
     "iopub.status.busy": "2025-05-11T16:24:57.081446Z",
     "iopub.status.idle": "2025-05-11T16:24:57.092626Z",
     "shell.execute_reply": "2025-05-11T16:24:57.092019Z",
     "shell.execute_reply.started": "2025-05-11T16:24:57.081889Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#we added a CNN Layer \n",
    "def cnn_bilstm():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=100, input_length=maxlen , mask_zero=True))\n",
    "    model.add(SpatialDropout1D(0.4))\n",
    "    model.add(Conv1D(filters=64, #no of filters\n",
    "                     kernel_size=5, #size of the filter\n",
    "                     activation='relu'))# activation function for non-linearity\n",
    "    #downsampling operation that reduces the spatial dimensions (sequence length) of the input while retaining the most important features.2 is the size of the pooling window\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Bidirectional(LSTM(64)))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(\n",
    "        loss=BinaryFocalCrossentropy(apply_class_balancing=True),\n",
    "        optimizer=Adam(learning_rate=0.0001),\n",
    "        metrics=['accuracy' , Precision() , Recall(thresholds=0)]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T16:24:57.093474Z",
     "iopub.status.busy": "2025-05-11T16:24:57.093275Z",
     "iopub.status.idle": "2025-05-11T16:24:57.104898Z",
     "shell.execute_reply": "2025-05-11T16:24:57.104303Z",
     "shell.execute_reply.started": "2025-05-11T16:24:57.093460Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# the same as the last model but adds L2 regularization \n",
    "# it penalize large weights in the model, which can help prevent overfitting.\n",
    "# we added it to all the layers\n",
    "L2_COEFF = 1e-4\n",
    "def cnn_bilstm2():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=100, input_length=maxlen, embeddings_regularizer=l2(L2_COEFF)))\n",
    "    model.add(SpatialDropout1D(0.4))\n",
    "    model.add(Conv1D(filters=64, kernel_size=5, activation='relu', kernel_regularizer=l2(L2_COEFF), bias_regularizer=l2(L2_COEFF)))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Bidirectional(LSTM(64, kernel_regularizer=l2(L2_COEFF), recurrent_regularizer=l2(L2_COEFF), bias_regularizer=l2(L2_COEFF))))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(64, activation='relu', kernel_regularizer=l2(L2_COEFF), bias_regularizer=l2(L2_COEFF)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(L2_COEFF), bias_regularizer=l2(L2_COEFF)))\n",
    "    \n",
    "    model.compile(\n",
    "        loss=BinaryFocalCrossentropy(apply_class_balancing=True),\n",
    "        optimizer=Adam(learning_rate=0.0001),\n",
    "        metrics=['accuracy', Precision(name='precision'), Recall(name='recall')]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T16:24:57.105805Z",
     "iopub.status.busy": "2025-05-11T16:24:57.105552Z",
     "iopub.status.idle": "2025-05-11T16:24:57.118079Z",
     "shell.execute_reply": "2025-05-11T16:24:57.117495Z",
     "shell.execute_reply.started": "2025-05-11T16:24:57.105783Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# same as the last model but with pre-trained embedding weights (Glove)\n",
    "# learning rate is higher because the embedding is not being trained\n",
    "L2_COEFF = 1e-4\n",
    "def pre_cnn_bilstm2():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=maxlen, weights=[embedding_matrix], trainable=False,mask_zero=True))\n",
    "    model.add(SpatialDropout1D(0.4))\n",
    "    model.add(Conv1D(filters=64, kernel_size=5, activation='relu', kernel_regularizer=l2(L2_COEFF), bias_regularizer=l2(L2_COEFF)))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Bidirectional(LSTM(64, kernel_regularizer=l2(L2_COEFF), recurrent_regularizer=l2(L2_COEFF), bias_regularizer=l2(L2_COEFF))))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(64, activation='relu', kernel_regularizer=l2(L2_COEFF), bias_regularizer=l2(L2_COEFF)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(L2_COEFF), bias_regularizer=l2(L2_COEFF)))\n",
    "    \n",
    "    model.compile(\n",
    "        loss=BinaryFocalCrossentropy(apply_class_balancing=True),\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        metrics=['accuracy', Precision(name='precision'), Recall(name='recall')]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T16:24:57.119001Z",
     "iopub.status.busy": "2025-05-11T16:24:57.118795Z",
     "iopub.status.idle": "2025-05-11T16:24:57.244948Z",
     "shell.execute_reply": "2025-05-11T16:24:57.244362Z",
     "shell.execute_reply.started": "2025-05-11T16:24:57.118980Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "models = {'CNN-BiLSTM' : cnn_bilstm2(),\n",
    "          'BiLSTM' : bilstm(),\n",
    "          'pre-CNN-BiLSTM' : pre_cnn_bilstm2(),\n",
    "          'pre-BiLSTM' : pre_bilstm()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T16:24:57.245807Z",
     "iopub.status.busy": "2025-05-11T16:24:57.245608Z",
     "iopub.status.idle": "2025-05-11T16:31:09.434224Z",
     "shell.execute_reply": "2025-05-11T16:31:09.433472Z",
     "shell.execute_reply.started": "2025-05-11T16:24:57.245791Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Epoch 1/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.4526 - loss: 0.2186 - precision: 0.5971 - recall: 0.1755 - val_accuracy: 0.4175 - val_loss: 0.2006 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.4217 - loss: 0.1970 - precision: 0.9268 - recall: 5.8408e-04 - val_accuracy: 0.4175 - val_loss: 0.1839 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.4150 - loss: 0.1808 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.4175 - val_loss: 0.1698 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.4151 - loss: 0.1670 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.4175 - val_loss: 0.1580 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.4135 - loss: 0.1559 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.4175 - val_loss: 0.1480 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.4134 - loss: 0.1463 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.4175 - val_loss: 0.1394 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.4153 - loss: 0.1379 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.4175 - val_loss: 0.1315 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.4199 - loss: 0.1295 - precision: 0.4492 - recall: 0.0039 - val_accuracy: 0.4962 - val_loss: 0.1218 - val_precision: 0.8651 - val_recall: 0.1601\n",
      "Epoch 9/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.5010 - loss: 0.1187 - precision: 0.8743 - recall: 0.1698 - val_accuracy: 0.6886 - val_loss: 0.1101 - val_precision: 0.8914 - val_recall: 0.5301\n",
      "Epoch 10/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.6602 - loss: 0.1077 - precision: 0.9194 - recall: 0.4518 - val_accuracy: 0.7468 - val_loss: 0.1009 - val_precision: 0.8921 - val_recall: 0.6432\n",
      "Epoch 11/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.7521 - loss: 0.0987 - precision: 0.9102 - recall: 0.6378 - val_accuracy: 0.7716 - val_loss: 0.0930 - val_precision: 0.9012 - val_recall: 0.6828\n",
      "Epoch 12/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.7979 - loss: 0.0900 - precision: 0.9210 - recall: 0.7133 - val_accuracy: 0.8195 - val_loss: 0.0875 - val_precision: 0.9052 - val_recall: 0.7709\n",
      "Epoch 13/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.8235 - loss: 0.0842 - precision: 0.9277 - recall: 0.7540 - val_accuracy: 0.8272 - val_loss: 0.0836 - val_precision: 0.9025 - val_recall: 0.7885\n",
      "Epoch 14/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.8448 - loss: 0.0780 - precision: 0.9393 - recall: 0.7829 - val_accuracy: 0.8409 - val_loss: 0.0808 - val_precision: 0.9024 - val_recall: 0.8150\n",
      "Epoch 15/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.8566 - loss: 0.0736 - precision: 0.9459 - recall: 0.7947 - val_accuracy: 0.8623 - val_loss: 0.0818 - val_precision: 0.8812 - val_recall: 0.8825\n",
      "Epoch 16/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.8803 - loss: 0.0693 - precision: 0.9542 - recall: 0.8392 - val_accuracy: 0.8683 - val_loss: 0.0815 - val_precision: 0.8892 - val_recall: 0.8840\n",
      "Epoch 17/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.8882 - loss: 0.0661 - precision: 0.9615 - recall: 0.8428 - val_accuracy: 0.8477 - val_loss: 0.0771 - val_precision: 0.9185 - val_recall: 0.8106\n",
      "Epoch 18/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.8955 - loss: 0.0630 - precision: 0.9695 - recall: 0.8469 - val_accuracy: 0.8648 - val_loss: 0.0780 - val_precision: 0.9017 - val_recall: 0.8620\n",
      "Epoch 19/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.9006 - loss: 0.0617 - precision: 0.9707 - recall: 0.8529 - val_accuracy: 0.8520 - val_loss: 0.0781 - val_precision: 0.9110 - val_recall: 0.8267\n",
      "Epoch 20/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9115 - loss: 0.0582 - precision: 0.9757 - recall: 0.8686 - val_accuracy: 0.8606 - val_loss: 0.0783 - val_precision: 0.9072 - val_recall: 0.8473\n",
      "Epoch 21/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9172 - loss: 0.0568 - precision: 0.9749 - recall: 0.8804 - val_accuracy: 0.8597 - val_loss: 0.0795 - val_precision: 0.9045 - val_recall: 0.8488\n",
      "Epoch 22/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9099 - loss: 0.0565 - precision: 0.9727 - recall: 0.8714 - val_accuracy: 0.8606 - val_loss: 0.0876 - val_precision: 0.8721 - val_recall: 0.8913\n",
      "Epoch 23/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9269 - loss: 0.0550 - precision: 0.9749 - recall: 0.8970 - val_accuracy: 0.8580 - val_loss: 0.0798 - val_precision: 0.9107 - val_recall: 0.8385\n",
      "Epoch 24/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9291 - loss: 0.0527 - precision: 0.9787 - recall: 0.8982 - val_accuracy: 0.8546 - val_loss: 0.0819 - val_precision: 0.9036 - val_recall: 0.8399\n",
      "Epoch 25/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9285 - loss: 0.0513 - precision: 0.9806 - recall: 0.8962 - val_accuracy: 0.8571 - val_loss: 0.0820 - val_precision: 0.9028 - val_recall: 0.8458\n",
      "Epoch 26/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9370 - loss: 0.0495 - precision: 0.9836 - recall: 0.9067 - val_accuracy: 0.8554 - val_loss: 0.0852 - val_precision: 0.8902 - val_recall: 0.8576\n",
      "Epoch 27/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9401 - loss: 0.0485 - precision: 0.9845 - recall: 0.9102 - val_accuracy: 0.8537 - val_loss: 0.0821 - val_precision: 0.9167 - val_recall: 0.8238\n",
      "Epoch 28/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9434 - loss: 0.0476 - precision: 0.9854 - recall: 0.9159 - val_accuracy: 0.8512 - val_loss: 0.0853 - val_precision: 0.8858 - val_recall: 0.8546\n",
      "Epoch 29/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9456 - loss: 0.0461 - precision: 0.9860 - recall: 0.9193 - val_accuracy: 0.8571 - val_loss: 0.0955 - val_precision: 0.8813 - val_recall: 0.8722\n",
      "Epoch 30/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9438 - loss: 0.0459 - precision: 0.9838 - recall: 0.9191 - val_accuracy: 0.8563 - val_loss: 0.0926 - val_precision: 0.8800 - val_recall: 0.8722\n",
      "Epoch 31/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9491 - loss: 0.0448 - precision: 0.9849 - recall: 0.9267 - val_accuracy: 0.8469 - val_loss: 0.0888 - val_precision: 0.9088 - val_recall: 0.8194\n",
      "Epoch 32/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9466 - loss: 0.0449 - precision: 0.9888 - recall: 0.9183 - val_accuracy: 0.8546 - val_loss: 0.0887 - val_precision: 0.8986 - val_recall: 0.8458\n",
      "Epoch 33/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9531 - loss: 0.0430 - precision: 0.9877 - recall: 0.9310 - val_accuracy: 0.8589 - val_loss: 0.0955 - val_precision: 0.8897 - val_recall: 0.8649\n",
      "Epoch 34/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9504 - loss: 0.0429 - precision: 0.9888 - recall: 0.9259 - val_accuracy: 0.8537 - val_loss: 0.0959 - val_precision: 0.8887 - val_recall: 0.8561\n",
      "Epoch 35/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9533 - loss: 0.0417 - precision: 0.9878 - recall: 0.9320 - val_accuracy: 0.8546 - val_loss: 0.0961 - val_precision: 0.8877 - val_recall: 0.8590\n",
      "Epoch 36/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9552 - loss: 0.0420 - precision: 0.9856 - recall: 0.9365 - val_accuracy: 0.8546 - val_loss: 0.0953 - val_precision: 0.8889 - val_recall: 0.8576\n",
      "Epoch 36: early stopping\n",
      "CNN-BiLSTM finished training\n",
      "CNN-BiLSTM saved to /kaggle/working/CNN-BiLSTM.h5\n",
      "--------------------------------------------------\n",
      "Epoch 1/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 56ms/step - accuracy: 0.4721 - loss: 0.0784 - precision: 0.5911 - recall: 0.3211 - val_accuracy: 0.4175 - val_loss: 0.0753 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.4180 - loss: 0.0748 - precision: 0.6098 - recall: 0.0014 - val_accuracy: 0.4175 - val_loss: 0.0716 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.4209 - loss: 0.0718 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.4175 - val_loss: 0.0701 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.4211 - loss: 0.0694 - precision: 0.3659 - recall: 2.9845e-04 - val_accuracy: 0.4328 - val_loss: 0.0628 - val_precision: 0.9500 - val_recall: 0.0279\n",
      "Epoch 5/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.5736 - loss: 0.0596 - precision: 0.9565 - recall: 0.2721 - val_accuracy: 0.6553 - val_loss: 0.0546 - val_precision: 0.9513 - val_recall: 0.4302\n",
      "Epoch 6/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.7442 - loss: 0.0509 - precision: 0.9360 - recall: 0.6048 - val_accuracy: 0.8075 - val_loss: 0.0472 - val_precision: 0.8878 - val_recall: 0.7665\n",
      "Epoch 7/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8286 - loss: 0.0428 - precision: 0.9207 - recall: 0.7737 - val_accuracy: 0.8135 - val_loss: 0.0433 - val_precision: 0.9217 - val_recall: 0.7430\n",
      "Epoch 8/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8457 - loss: 0.0366 - precision: 0.9393 - recall: 0.7872 - val_accuracy: 0.8238 - val_loss: 0.0405 - val_precision: 0.9218 - val_recall: 0.7621\n",
      "Epoch 9/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8574 - loss: 0.0333 - precision: 0.9489 - recall: 0.7988 - val_accuracy: 0.8272 - val_loss: 0.0392 - val_precision: 0.9209 - val_recall: 0.7695\n",
      "Epoch 10/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8705 - loss: 0.0308 - precision: 0.9550 - recall: 0.8197 - val_accuracy: 0.8306 - val_loss: 0.0413 - val_precision: 0.9244 - val_recall: 0.7724\n",
      "Epoch 11/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8879 - loss: 0.0269 - precision: 0.9634 - recall: 0.8405 - val_accuracy: 0.8383 - val_loss: 0.0406 - val_precision: 0.9198 - val_recall: 0.7915\n",
      "Epoch 12/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8962 - loss: 0.0251 - precision: 0.9684 - recall: 0.8485 - val_accuracy: 0.8409 - val_loss: 0.0440 - val_precision: 0.9202 - val_recall: 0.7959\n",
      "Epoch 13/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9068 - loss: 0.0232 - precision: 0.9708 - recall: 0.8663 - val_accuracy: 0.8452 - val_loss: 0.0415 - val_precision: 0.9112 - val_recall: 0.8135\n",
      "Epoch 14/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9049 - loss: 0.0226 - precision: 0.9702 - recall: 0.8623 - val_accuracy: 0.8426 - val_loss: 0.0431 - val_precision: 0.9176 - val_recall: 0.8018\n",
      "Epoch 15/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9180 - loss: 0.0202 - precision: 0.9752 - recall: 0.8818 - val_accuracy: 0.8520 - val_loss: 0.0448 - val_precision: 0.9097 - val_recall: 0.8282\n",
      "Epoch 16/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9275 - loss: 0.0189 - precision: 0.9781 - recall: 0.8958 - val_accuracy: 0.8571 - val_loss: 0.0480 - val_precision: 0.9041 - val_recall: 0.8443\n",
      "Epoch 17/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9300 - loss: 0.0179 - precision: 0.9796 - recall: 0.8981 - val_accuracy: 0.8460 - val_loss: 0.0473 - val_precision: 0.9224 - val_recall: 0.8032\n",
      "Epoch 18/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9302 - loss: 0.0174 - precision: 0.9805 - recall: 0.8965 - val_accuracy: 0.8546 - val_loss: 0.0539 - val_precision: 0.9011 - val_recall: 0.8429\n",
      "Epoch 19/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9358 - loss: 0.0161 - precision: 0.9792 - recall: 0.9083 - val_accuracy: 0.8537 - val_loss: 0.0546 - val_precision: 0.8972 - val_recall: 0.8458\n",
      "Epoch 20/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.9355 - loss: 0.0157 - precision: 0.9811 - recall: 0.9077 - val_accuracy: 0.8580 - val_loss: 0.0574 - val_precision: 0.9055 - val_recall: 0.8443\n",
      "Epoch 21/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9443 - loss: 0.0139 - precision: 0.9848 - recall: 0.9191 - val_accuracy: 0.8537 - val_loss: 0.0550 - val_precision: 0.9035 - val_recall: 0.8385\n",
      "Epoch 22/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9457 - loss: 0.0146 - precision: 0.9821 - recall: 0.9237 - val_accuracy: 0.8452 - val_loss: 0.0543 - val_precision: 0.9139 - val_recall: 0.8106\n",
      "Epoch 23/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9438 - loss: 0.0134 - precision: 0.9863 - recall: 0.9163 - val_accuracy: 0.8589 - val_loss: 0.0591 - val_precision: 0.9108 - val_recall: 0.8399\n",
      "Epoch 24/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9469 - loss: 0.0130 - precision: 0.9837 - recall: 0.9252 - val_accuracy: 0.8477 - val_loss: 0.0604 - val_precision: 0.9199 - val_recall: 0.8091\n",
      "Epoch 25/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9478 - loss: 0.0125 - precision: 0.9861 - recall: 0.9249 - val_accuracy: 0.8520 - val_loss: 0.0596 - val_precision: 0.9123 - val_recall: 0.8253\n",
      "Epoch 26/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9543 - loss: 0.0124 - precision: 0.9895 - recall: 0.9309 - val_accuracy: 0.8503 - val_loss: 0.0657 - val_precision: 0.9068 - val_recall: 0.8282\n",
      "Epoch 27/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9557 - loss: 0.0111 - precision: 0.9896 - recall: 0.9336 - val_accuracy: 0.8546 - val_loss: 0.0710 - val_precision: 0.8889 - val_recall: 0.8576\n",
      "Epoch 28/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9581 - loss: 0.0114 - precision: 0.9889 - recall: 0.9386 - val_accuracy: 0.8435 - val_loss: 0.0726 - val_precision: 0.8978 - val_recall: 0.8253\n",
      "Epoch 29/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9593 - loss: 0.0110 - precision: 0.9890 - recall: 0.9397 - val_accuracy: 0.8443 - val_loss: 0.0730 - val_precision: 0.8868 - val_recall: 0.8399\n",
      "Epoch 30/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9596 - loss: 0.0109 - precision: 0.9873 - recall: 0.9429 - val_accuracy: 0.8443 - val_loss: 0.0726 - val_precision: 0.8929 - val_recall: 0.8326\n",
      "Epoch 31/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9617 - loss: 0.0094 - precision: 0.9896 - recall: 0.9439 - val_accuracy: 0.8512 - val_loss: 0.0819 - val_precision: 0.8801 - val_recall: 0.8620\n",
      "Epoch 32/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9677 - loss: 0.0084 - precision: 0.9915 - recall: 0.9526 - val_accuracy: 0.8494 - val_loss: 0.0855 - val_precision: 0.8879 - val_recall: 0.8488\n",
      "Epoch 33/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9699 - loss: 0.0087 - precision: 0.9908 - recall: 0.9576 - val_accuracy: 0.8477 - val_loss: 0.0812 - val_precision: 0.8986 - val_recall: 0.8326\n",
      "Epoch 34/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9683 - loss: 0.0084 - precision: 0.9946 - recall: 0.9503 - val_accuracy: 0.8469 - val_loss: 0.0793 - val_precision: 0.8885 - val_recall: 0.8429\n",
      "Epoch 35/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9694 - loss: 0.0087 - precision: 0.9909 - recall: 0.9558 - val_accuracy: 0.8486 - val_loss: 0.0842 - val_precision: 0.8975 - val_recall: 0.8355\n",
      "Epoch 36/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9710 - loss: 0.0077 - precision: 0.9923 - recall: 0.9578 - val_accuracy: 0.8512 - val_loss: 0.0966 - val_precision: 0.8870 - val_recall: 0.8532\n",
      "Epoch 37/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9702 - loss: 0.0078 - precision: 0.9922 - recall: 0.9567 - val_accuracy: 0.8512 - val_loss: 0.0922 - val_precision: 0.8906 - val_recall: 0.8488\n",
      "Epoch 38/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9706 - loss: 0.0081 - precision: 0.9924 - recall: 0.9576 - val_accuracy: 0.8486 - val_loss: 0.0847 - val_precision: 0.8938 - val_recall: 0.8399\n",
      "Epoch 39/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9744 - loss: 0.0072 - precision: 0.9937 - recall: 0.9621 - val_accuracy: 0.8503 - val_loss: 0.0949 - val_precision: 0.8857 - val_recall: 0.8532\n",
      "Epoch 40/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9732 - loss: 0.0075 - precision: 0.9913 - recall: 0.9622 - val_accuracy: 0.8452 - val_loss: 0.1047 - val_precision: 0.8799 - val_recall: 0.8502\n",
      "Epoch 41/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.9712 - loss: 0.0071 - precision: 0.9915 - recall: 0.9591 - val_accuracy: 0.8529 - val_loss: 0.0953 - val_precision: 0.8897 - val_recall: 0.8532\n",
      "Epoch 42/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9763 - loss: 0.0070 - precision: 0.9946 - recall: 0.9645 - val_accuracy: 0.8426 - val_loss: 0.0952 - val_precision: 0.8877 - val_recall: 0.8355\n",
      "Epoch 43/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9760 - loss: 0.0062 - precision: 0.9931 - recall: 0.9660 - val_accuracy: 0.8494 - val_loss: 0.1081 - val_precision: 0.8741 - val_recall: 0.8664\n",
      "Epoch 43: early stopping\n",
      "BiLSTM finished training\n",
      "BiLSTM saved to /kaggle/working/BiLSTM.h5\n",
      "--------------------------------------------------\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'conv1d_5' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 70ms/step - accuracy: 0.4422 - loss: 0.1365 - precision: 0.5758 - recall: 0.1273 - val_accuracy: 0.4175 - val_loss: 0.1163 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.4243 - loss: 0.1148 - precision: 0.7393 - recall: 0.0298 - val_accuracy: 0.4525 - val_loss: 0.1008 - val_precision: 0.9020 - val_recall: 0.0675\n",
      "Epoch 3/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.4837 - loss: 0.1024 - precision: 0.7917 - recall: 0.1639 - val_accuracy: 0.5731 - val_loss: 0.0906 - val_precision: 0.9062 - val_recall: 0.2981\n",
      "Epoch 4/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.5717 - loss: 0.0933 - precision: 0.8267 - recall: 0.3285 - val_accuracy: 0.7032 - val_loss: 0.0843 - val_precision: 0.8494 - val_recall: 0.5962\n",
      "Epoch 5/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.6270 - loss: 0.0866 - precision: 0.8394 - recall: 0.4496 - val_accuracy: 0.6681 - val_loss: 0.0788 - val_precision: 0.8907 - val_recall: 0.4905\n",
      "Epoch 6/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.6351 - loss: 0.0826 - precision: 0.8541 - recall: 0.4501 - val_accuracy: 0.6989 - val_loss: 0.0759 - val_precision: 0.9102 - val_recall: 0.5360\n",
      "Epoch 7/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.6502 - loss: 0.0797 - precision: 0.8690 - recall: 0.4820 - val_accuracy: 0.7562 - val_loss: 0.0764 - val_precision: 0.8750 - val_recall: 0.6784\n",
      "Epoch 8/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.6830 - loss: 0.0740 - precision: 0.8904 - recall: 0.5238 - val_accuracy: 0.7819 - val_loss: 0.0705 - val_precision: 0.8845 - val_recall: 0.7195\n",
      "Epoch 9/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7151 - loss: 0.0712 - precision: 0.8833 - recall: 0.5853 - val_accuracy: 0.7374 - val_loss: 0.0659 - val_precision: 0.9231 - val_recall: 0.5991\n",
      "Epoch 10/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7181 - loss: 0.0680 - precision: 0.9010 - recall: 0.5730 - val_accuracy: 0.7810 - val_loss: 0.0628 - val_precision: 0.9079 - val_recall: 0.6946\n",
      "Epoch 11/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.7296 - loss: 0.0661 - precision: 0.8987 - recall: 0.6055 - val_accuracy: 0.8186 - val_loss: 0.0654 - val_precision: 0.8740 - val_recall: 0.8047\n",
      "Epoch 12/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7335 - loss: 0.0656 - precision: 0.8952 - recall: 0.6077 - val_accuracy: 0.8195 - val_loss: 0.0633 - val_precision: 0.8730 - val_recall: 0.8076\n",
      "Epoch 13/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7545 - loss: 0.0616 - precision: 0.8991 - recall: 0.6576 - val_accuracy: 0.7750 - val_loss: 0.0583 - val_precision: 0.9197 - val_recall: 0.6725\n",
      "Epoch 14/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.7471 - loss: 0.0618 - precision: 0.9082 - recall: 0.6280 - val_accuracy: 0.7391 - val_loss: 0.0573 - val_precision: 0.9519 - val_recall: 0.5815\n",
      "Epoch 15/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.7462 - loss: 0.0613 - precision: 0.9105 - recall: 0.6324 - val_accuracy: 0.7913 - val_loss: 0.0565 - val_precision: 0.9344 - val_recall: 0.6902\n",
      "Epoch 16/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.7555 - loss: 0.0601 - precision: 0.9047 - recall: 0.6511 - val_accuracy: 0.7947 - val_loss: 0.0572 - val_precision: 0.9106 - val_recall: 0.7181\n",
      "Epoch 17/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7660 - loss: 0.0586 - precision: 0.9179 - recall: 0.6492 - val_accuracy: 0.8229 - val_loss: 0.0547 - val_precision: 0.8990 - val_recall: 0.7841\n",
      "Epoch 18/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.7669 - loss: 0.0569 - precision: 0.9152 - recall: 0.6647 - val_accuracy: 0.8033 - val_loss: 0.0561 - val_precision: 0.9138 - val_recall: 0.7313\n",
      "Epoch 19/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.7772 - loss: 0.0552 - precision: 0.9267 - recall: 0.6678 - val_accuracy: 0.8315 - val_loss: 0.0534 - val_precision: 0.9130 - val_recall: 0.7856\n",
      "Epoch 20/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.7794 - loss: 0.0545 - precision: 0.9245 - recall: 0.6751 - val_accuracy: 0.8041 - val_loss: 0.0519 - val_precision: 0.9346 - val_recall: 0.7137\n",
      "Epoch 21/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7767 - loss: 0.0545 - precision: 0.9179 - recall: 0.6805 - val_accuracy: 0.8015 - val_loss: 0.0522 - val_precision: 0.9342 - val_recall: 0.7093\n",
      "Epoch 22/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.7858 - loss: 0.0540 - precision: 0.9198 - recall: 0.6931 - val_accuracy: 0.8135 - val_loss: 0.0504 - val_precision: 0.9311 - val_recall: 0.7342\n",
      "Epoch 23/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7833 - loss: 0.0531 - precision: 0.9231 - recall: 0.6830 - val_accuracy: 0.8178 - val_loss: 0.0515 - val_precision: 0.9021 - val_recall: 0.7709\n",
      "Epoch 24/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7865 - loss: 0.0532 - precision: 0.9198 - recall: 0.6997 - val_accuracy: 0.8127 - val_loss: 0.0526 - val_precision: 0.9170 - val_recall: 0.7460\n",
      "Epoch 25/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7893 - loss: 0.0534 - precision: 0.9137 - recall: 0.7048 - val_accuracy: 0.7998 - val_loss: 0.0518 - val_precision: 0.9056 - val_recall: 0.7327\n",
      "Epoch 26/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7930 - loss: 0.0511 - precision: 0.9309 - recall: 0.6976 - val_accuracy: 0.8349 - val_loss: 0.0497 - val_precision: 0.9164 - val_recall: 0.7885\n",
      "Epoch 27/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7933 - loss: 0.0511 - precision: 0.9250 - recall: 0.7031 - val_accuracy: 0.8263 - val_loss: 0.0530 - val_precision: 0.9024 - val_recall: 0.7871\n",
      "Epoch 28/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7842 - loss: 0.0532 - precision: 0.9206 - recall: 0.6841 - val_accuracy: 0.8272 - val_loss: 0.0535 - val_precision: 0.9012 - val_recall: 0.7900\n",
      "Epoch 29/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7882 - loss: 0.0526 - precision: 0.9134 - recall: 0.7022 - val_accuracy: 0.7990 - val_loss: 0.0488 - val_precision: 0.9373 - val_recall: 0.7019\n",
      "Epoch 30/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8134 - loss: 0.0499 - precision: 0.9330 - recall: 0.7342 - val_accuracy: 0.7879 - val_loss: 0.0480 - val_precision: 0.9446 - val_recall: 0.6755\n",
      "Epoch 31/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7990 - loss: 0.0491 - precision: 0.9372 - recall: 0.7056 - val_accuracy: 0.8152 - val_loss: 0.0471 - val_precision: 0.9379 - val_recall: 0.7313\n",
      "Epoch 32/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8047 - loss: 0.0493 - precision: 0.9342 - recall: 0.7145 - val_accuracy: 0.8460 - val_loss: 0.0482 - val_precision: 0.9073 - val_recall: 0.8194\n",
      "Epoch 33/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8057 - loss: 0.0492 - precision: 0.9289 - recall: 0.7222 - val_accuracy: 0.7793 - val_loss: 0.0491 - val_precision: 0.9548 - val_recall: 0.6520\n",
      "Epoch 34/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7987 - loss: 0.0494 - precision: 0.9370 - recall: 0.7023 - val_accuracy: 0.7776 - val_loss: 0.0480 - val_precision: 0.9507 - val_recall: 0.6520\n",
      "Epoch 35/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7998 - loss: 0.0490 - precision: 0.9358 - recall: 0.7058 - val_accuracy: 0.8015 - val_loss: 0.0474 - val_precision: 0.9463 - val_recall: 0.6990\n",
      "Epoch 36/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.8069 - loss: 0.0486 - precision: 0.9302 - recall: 0.7248 - val_accuracy: 0.8075 - val_loss: 0.0461 - val_precision: 0.9419 - val_recall: 0.7137\n",
      "Epoch 37/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7707 - loss: 0.0527 - precision: 0.9269 - recall: 0.6549 - val_accuracy: 0.8067 - val_loss: 0.0476 - val_precision: 0.9470 - val_recall: 0.7078\n",
      "Epoch 38/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8012 - loss: 0.0508 - precision: 0.9329 - recall: 0.7142 - val_accuracy: 0.7947 - val_loss: 0.0490 - val_precision: 0.9509 - val_recall: 0.6828\n",
      "Epoch 39/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8078 - loss: 0.0486 - precision: 0.9352 - recall: 0.7166 - val_accuracy: 0.8204 - val_loss: 0.0455 - val_precision: 0.9385 - val_recall: 0.7401\n",
      "Epoch 40/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8117 - loss: 0.0473 - precision: 0.9378 - recall: 0.7272 - val_accuracy: 0.8152 - val_loss: 0.0462 - val_precision: 0.9532 - val_recall: 0.7181\n",
      "Epoch 41/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8140 - loss: 0.0474 - precision: 0.9371 - recall: 0.7318 - val_accuracy: 0.7904 - val_loss: 0.0467 - val_precision: 0.9467 - val_recall: 0.6784\n",
      "Epoch 42/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8088 - loss: 0.0473 - precision: 0.9447 - recall: 0.7134 - val_accuracy: 0.8400 - val_loss: 0.0494 - val_precision: 0.8971 - val_recall: 0.8194\n",
      "Epoch 43/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8079 - loss: 0.0486 - precision: 0.9328 - recall: 0.7241 - val_accuracy: 0.8460 - val_loss: 0.0521 - val_precision: 0.8756 - val_recall: 0.8576\n",
      "Epoch 44/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8182 - loss: 0.0485 - precision: 0.9310 - recall: 0.7434 - val_accuracy: 0.8238 - val_loss: 0.0470 - val_precision: 0.9406 - val_recall: 0.7445\n",
      "Epoch 45/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8084 - loss: 0.0482 - precision: 0.9255 - recall: 0.7292 - val_accuracy: 0.8152 - val_loss: 0.0463 - val_precision: 0.9412 - val_recall: 0.7283\n",
      "Epoch 46/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8078 - loss: 0.0477 - precision: 0.9375 - recall: 0.7161 - val_accuracy: 0.8144 - val_loss: 0.0469 - val_precision: 0.9462 - val_recall: 0.7225\n",
      "Epoch 47/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8035 - loss: 0.0476 - precision: 0.9402 - recall: 0.7004 - val_accuracy: 0.8178 - val_loss: 0.0454 - val_precision: 0.9466 - val_recall: 0.7283\n",
      "Epoch 48/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8203 - loss: 0.0460 - precision: 0.9379 - recall: 0.7390 - val_accuracy: 0.8246 - val_loss: 0.0455 - val_precision: 0.9359 - val_recall: 0.7504\n",
      "Epoch 49/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8249 - loss: 0.0464 - precision: 0.9426 - recall: 0.7473 - val_accuracy: 0.8221 - val_loss: 0.0452 - val_precision: 0.9471 - val_recall: 0.7357\n",
      "Epoch 50/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8177 - loss: 0.0462 - precision: 0.9396 - recall: 0.7368 - val_accuracy: 0.7716 - val_loss: 0.0476 - val_precision: 0.9580 - val_recall: 0.6358\n",
      "Epoch 51/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8013 - loss: 0.0469 - precision: 0.9457 - recall: 0.6962 - val_accuracy: 0.8460 - val_loss: 0.0471 - val_precision: 0.8970 - val_recall: 0.8311\n",
      "Epoch 52/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8124 - loss: 0.0479 - precision: 0.9330 - recall: 0.7308 - val_accuracy: 0.8212 - val_loss: 0.0450 - val_precision: 0.9387 - val_recall: 0.7416\n",
      "Epoch 53/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8142 - loss: 0.0462 - precision: 0.9392 - recall: 0.7296 - val_accuracy: 0.8426 - val_loss: 0.0468 - val_precision: 0.9121 - val_recall: 0.8076\n",
      "Epoch 54/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8230 - loss: 0.0461 - precision: 0.9397 - recall: 0.7425 - val_accuracy: 0.8204 - val_loss: 0.0449 - val_precision: 0.9435 - val_recall: 0.7357\n",
      "Epoch 55/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8321 - loss: 0.0450 - precision: 0.9422 - recall: 0.7587 - val_accuracy: 0.7921 - val_loss: 0.0469 - val_precision: 0.9506 - val_recall: 0.6784\n",
      "Epoch 56/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8185 - loss: 0.0459 - precision: 0.9370 - recall: 0.7354 - val_accuracy: 0.8503 - val_loss: 0.0492 - val_precision: 0.9029 - val_recall: 0.8326\n",
      "Epoch 57/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8311 - loss: 0.0443 - precision: 0.9416 - recall: 0.7587 - val_accuracy: 0.8392 - val_loss: 0.0471 - val_precision: 0.9302 - val_recall: 0.7827\n",
      "Epoch 58/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8263 - loss: 0.0438 - precision: 0.9465 - recall: 0.7437 - val_accuracy: 0.7853 - val_loss: 0.0467 - val_precision: 0.9654 - val_recall: 0.6549\n",
      "Epoch 59/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8153 - loss: 0.0461 - precision: 0.9452 - recall: 0.7239 - val_accuracy: 0.8469 - val_loss: 0.0492 - val_precision: 0.8959 - val_recall: 0.8341\n",
      "Epoch 60/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8295 - loss: 0.0453 - precision: 0.9362 - recall: 0.7611 - val_accuracy: 0.8127 - val_loss: 0.0472 - val_precision: 0.9358 - val_recall: 0.7283\n",
      "Epoch 61/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8265 - loss: 0.0463 - precision: 0.9428 - recall: 0.7449 - val_accuracy: 0.8092 - val_loss: 0.0461 - val_precision: 0.9508 - val_recall: 0.7093\n",
      "Epoch 62/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8240 - loss: 0.0448 - precision: 0.9407 - recall: 0.7453 - val_accuracy: 0.8392 - val_loss: 0.0468 - val_precision: 0.9243 - val_recall: 0.7885\n",
      "Epoch 63/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8369 - loss: 0.0442 - precision: 0.9398 - recall: 0.7671 - val_accuracy: 0.8281 - val_loss: 0.0451 - val_precision: 0.9364 - val_recall: 0.7562\n",
      "Epoch 63: early stopping\n",
      "pre-CNN-BiLSTM finished training\n",
      "pre-CNN-BiLSTM saved to /kaggle/working/pre-CNN-BiLSTM.h5\n",
      "--------------------------------------------------\n",
      "Epoch 1/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - accuracy: 0.4493 - loss: 0.0796 - precision: 0.6056 - recall: 0.1796 - val_accuracy: 0.4175 - val_loss: 0.0708 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.4467 - loss: 0.0717 - precision: 0.7239 - recall: 0.0535 - val_accuracy: 0.4251 - val_loss: 0.0684 - val_precision: 1.0000 - val_recall: 0.0132\n",
      "Epoch 3/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.4752 - loss: 0.0699 - precision: 0.8032 - recall: 0.1208 - val_accuracy: 0.5295 - val_loss: 0.0639 - val_precision: 0.9172 - val_recall: 0.2115\n",
      "Epoch 4/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.5427 - loss: 0.0666 - precision: 0.8219 - recall: 0.2830 - val_accuracy: 0.6373 - val_loss: 0.0586 - val_precision: 0.9054 - val_recall: 0.4214\n",
      "Epoch 5/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.6169 - loss: 0.0628 - precision: 0.8559 - recall: 0.4012 - val_accuracy: 0.7117 - val_loss: 0.0557 - val_precision: 0.8755 - val_recall: 0.5888\n",
      "Epoch 6/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.6446 - loss: 0.0603 - precision: 0.8634 - recall: 0.4628 - val_accuracy: 0.7126 - val_loss: 0.0526 - val_precision: 0.9117 - val_recall: 0.5609\n",
      "Epoch 7/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.6580 - loss: 0.0586 - precision: 0.8792 - recall: 0.4891 - val_accuracy: 0.7271 - val_loss: 0.0508 - val_precision: 0.9229 - val_recall: 0.5800\n",
      "Epoch 8/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.6838 - loss: 0.0564 - precision: 0.8661 - recall: 0.5378 - val_accuracy: 0.7023 - val_loss: 0.0542 - val_precision: 0.9464 - val_recall: 0.5184\n",
      "Epoch 9/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.6813 - loss: 0.0557 - precision: 0.8773 - recall: 0.5263 - val_accuracy: 0.7331 - val_loss: 0.0484 - val_precision: 0.9424 - val_recall: 0.5771\n",
      "Epoch 10/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7081 - loss: 0.0531 - precision: 0.8956 - recall: 0.5644 - val_accuracy: 0.7203 - val_loss: 0.0470 - val_precision: 0.9538 - val_recall: 0.5463\n",
      "Epoch 11/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7064 - loss: 0.0522 - precision: 0.9051 - recall: 0.5515 - val_accuracy: 0.7263 - val_loss: 0.0465 - val_precision: 0.9570 - val_recall: 0.5551\n",
      "Epoch 12/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7216 - loss: 0.0503 - precision: 0.9069 - recall: 0.5709 - val_accuracy: 0.7280 - val_loss: 0.0455 - val_precision: 0.9481 - val_recall: 0.5639\n",
      "Epoch 13/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7401 - loss: 0.0485 - precision: 0.9226 - recall: 0.6061 - val_accuracy: 0.7451 - val_loss: 0.0439 - val_precision: 0.9382 - val_recall: 0.6021\n",
      "Epoch 14/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.7430 - loss: 0.0475 - precision: 0.9206 - recall: 0.6091 - val_accuracy: 0.7451 - val_loss: 0.0425 - val_precision: 0.9464 - val_recall: 0.5962\n",
      "Epoch 15/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7581 - loss: 0.0461 - precision: 0.9189 - recall: 0.6436 - val_accuracy: 0.7990 - val_loss: 0.0426 - val_precision: 0.9145 - val_recall: 0.7225\n",
      "Epoch 16/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7480 - loss: 0.0478 - precision: 0.9193 - recall: 0.6259 - val_accuracy: 0.7528 - val_loss: 0.0430 - val_precision: 0.9395 - val_recall: 0.6153\n",
      "Epoch 17/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7624 - loss: 0.0460 - precision: 0.9196 - recall: 0.6495 - val_accuracy: 0.7844 - val_loss: 0.0408 - val_precision: 0.9264 - val_recall: 0.6843\n",
      "Epoch 18/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7545 - loss: 0.0458 - precision: 0.9213 - recall: 0.6363 - val_accuracy: 0.7759 - val_loss: 0.0407 - val_precision: 0.9392 - val_recall: 0.6579\n",
      "Epoch 19/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7657 - loss: 0.0454 - precision: 0.9268 - recall: 0.6490 - val_accuracy: 0.7408 - val_loss: 0.0417 - val_precision: 0.9655 - val_recall: 0.5756\n",
      "Epoch 20/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7432 - loss: 0.0457 - precision: 0.9318 - recall: 0.5998 - val_accuracy: 0.7186 - val_loss: 0.0435 - val_precision: 0.9706 - val_recall: 0.5330\n",
      "Epoch 21/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7647 - loss: 0.0441 - precision: 0.9311 - recall: 0.6428 - val_accuracy: 0.7579 - val_loss: 0.0408 - val_precision: 0.9585 - val_recall: 0.6109\n",
      "Epoch 22/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7661 - loss: 0.0440 - precision: 0.9220 - recall: 0.6552 - val_accuracy: 0.7904 - val_loss: 0.0401 - val_precision: 0.9395 - val_recall: 0.6843\n",
      "Epoch 23/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7769 - loss: 0.0435 - precision: 0.9322 - recall: 0.6629 - val_accuracy: 0.7665 - val_loss: 0.0408 - val_precision: 0.9615 - val_recall: 0.6241\n",
      "Epoch 24/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7819 - loss: 0.0427 - precision: 0.9337 - recall: 0.6764 - val_accuracy: 0.8169 - val_loss: 0.0391 - val_precision: 0.9300 - val_recall: 0.7416\n",
      "Epoch 25/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7823 - loss: 0.0416 - precision: 0.9345 - recall: 0.6791 - val_accuracy: 0.7810 - val_loss: 0.0391 - val_precision: 0.9590 - val_recall: 0.6520\n",
      "Epoch 26/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7770 - loss: 0.0426 - precision: 0.9324 - recall: 0.6693 - val_accuracy: 0.7861 - val_loss: 0.0381 - val_precision: 0.9575 - val_recall: 0.6623\n",
      "Epoch 27/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7854 - loss: 0.0427 - precision: 0.9377 - recall: 0.6763 - val_accuracy: 0.8084 - val_loss: 0.0386 - val_precision: 0.9420 - val_recall: 0.7151\n",
      "Epoch 28/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7908 - loss: 0.0413 - precision: 0.9324 - recall: 0.6935 - val_accuracy: 0.7827 - val_loss: 0.0391 - val_precision: 0.9439 - val_recall: 0.6667\n",
      "Epoch 29/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7939 - loss: 0.0402 - precision: 0.9414 - recall: 0.6893 - val_accuracy: 0.7733 - val_loss: 0.0386 - val_precision: 0.9602 - val_recall: 0.6373\n",
      "Epoch 30/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7819 - loss: 0.0409 - precision: 0.9392 - recall: 0.6702 - val_accuracy: 0.8221 - val_loss: 0.0375 - val_precision: 0.9437 - val_recall: 0.7386\n",
      "Epoch 31/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.7908 - loss: 0.0403 - precision: 0.9441 - recall: 0.6790 - val_accuracy: 0.7913 - val_loss: 0.0374 - val_precision: 0.9524 - val_recall: 0.6755\n",
      "Epoch 32/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8026 - loss: 0.0393 - precision: 0.9383 - recall: 0.7101 - val_accuracy: 0.7485 - val_loss: 0.0399 - val_precision: 0.9685 - val_recall: 0.5874\n",
      "Epoch 33/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7793 - loss: 0.0406 - precision: 0.9479 - recall: 0.6618 - val_accuracy: 0.8204 - val_loss: 0.0366 - val_precision: 0.9418 - val_recall: 0.7372\n",
      "Epoch 34/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8009 - loss: 0.0394 - precision: 0.9430 - recall: 0.7013 - val_accuracy: 0.8169 - val_loss: 0.0369 - val_precision: 0.9499 - val_recall: 0.7239\n",
      "Epoch 35/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8164 - loss: 0.0379 - precision: 0.9493 - recall: 0.7240 - val_accuracy: 0.7810 - val_loss: 0.0376 - val_precision: 0.9531 - val_recall: 0.6564\n",
      "Epoch 36/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7977 - loss: 0.0394 - precision: 0.9420 - recall: 0.6964 - val_accuracy: 0.8135 - val_loss: 0.0368 - val_precision: 0.9495 - val_recall: 0.7181\n",
      "Epoch 37/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8091 - loss: 0.0384 - precision: 0.9418 - recall: 0.7130 - val_accuracy: 0.8435 - val_loss: 0.0378 - val_precision: 0.9446 - val_recall: 0.7768\n",
      "Epoch 38/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8068 - loss: 0.0389 - precision: 0.9366 - recall: 0.7191 - val_accuracy: 0.7750 - val_loss: 0.0379 - val_precision: 0.9604 - val_recall: 0.6402\n",
      "Epoch 39/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7954 - loss: 0.0379 - precision: 0.9496 - recall: 0.6849 - val_accuracy: 0.7964 - val_loss: 0.0362 - val_precision: 0.9567 - val_recall: 0.6814\n",
      "Epoch 40/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.8133 - loss: 0.0368 - precision: 0.9527 - recall: 0.7160 - val_accuracy: 0.8375 - val_loss: 0.0380 - val_precision: 0.9408 - val_recall: 0.7695\n",
      "Epoch 41/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8171 - loss: 0.0373 - precision: 0.9438 - recall: 0.7291 - val_accuracy: 0.8272 - val_loss: 0.0370 - val_precision: 0.9510 - val_recall: 0.7416\n",
      "Epoch 42/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8179 - loss: 0.0363 - precision: 0.9522 - recall: 0.7229 - val_accuracy: 0.8109 - val_loss: 0.0370 - val_precision: 0.9545 - val_recall: 0.7093\n",
      "Epoch 43/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8084 - loss: 0.0374 - precision: 0.9429 - recall: 0.7104 - val_accuracy: 0.8161 - val_loss: 0.0363 - val_precision: 0.9587 - val_recall: 0.7151\n",
      "Epoch 44/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8255 - loss: 0.0345 - precision: 0.9519 - recall: 0.7328 - val_accuracy: 0.8417 - val_loss: 0.0380 - val_precision: 0.9351 - val_recall: 0.7827\n",
      "Epoch 45/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8153 - loss: 0.0383 - precision: 0.9355 - recall: 0.7263 - val_accuracy: 0.8529 - val_loss: 0.0387 - val_precision: 0.9396 - val_recall: 0.7988\n",
      "Epoch 46/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8278 - loss: 0.0356 - precision: 0.9505 - recall: 0.7413 - val_accuracy: 0.7861 - val_loss: 0.0364 - val_precision: 0.9615 - val_recall: 0.6593\n",
      "Epoch 47/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8187 - loss: 0.0349 - precision: 0.9568 - recall: 0.7221 - val_accuracy: 0.8144 - val_loss: 0.0373 - val_precision: 0.9585 - val_recall: 0.7122\n",
      "Epoch 48/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8179 - loss: 0.0350 - precision: 0.9607 - recall: 0.7191 - val_accuracy: 0.7998 - val_loss: 0.0366 - val_precision: 0.9647 - val_recall: 0.6814\n",
      "Epoch 49/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8222 - loss: 0.0354 - precision: 0.9553 - recall: 0.7302 - val_accuracy: 0.8289 - val_loss: 0.0362 - val_precision: 0.9495 - val_recall: 0.7460\n",
      "Epoch 50/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8289 - loss: 0.0341 - precision: 0.9535 - recall: 0.7415 - val_accuracy: 0.8263 - val_loss: 0.0377 - val_precision: 0.9361 - val_recall: 0.7533\n",
      "Epoch 51/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8231 - loss: 0.0348 - precision: 0.9586 - recall: 0.7276 - val_accuracy: 0.8041 - val_loss: 0.0367 - val_precision: 0.9538 - val_recall: 0.6975\n",
      "Epoch 52/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8297 - loss: 0.0342 - precision: 0.9515 - recall: 0.7450 - val_accuracy: 0.8383 - val_loss: 0.0358 - val_precision: 0.9393 - val_recall: 0.7724\n",
      "Epoch 53/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8333 - loss: 0.0343 - precision: 0.9507 - recall: 0.7515 - val_accuracy: 0.8580 - val_loss: 0.0380 - val_precision: 0.9402 - val_recall: 0.8076\n",
      "Epoch 54/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8352 - loss: 0.0325 - precision: 0.9564 - recall: 0.7536 - val_accuracy: 0.8417 - val_loss: 0.0374 - val_precision: 0.9526 - val_recall: 0.7665\n",
      "Epoch 55/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8335 - loss: 0.0335 - precision: 0.9600 - recall: 0.7443 - val_accuracy: 0.8298 - val_loss: 0.0374 - val_precision: 0.9446 - val_recall: 0.7518\n",
      "Epoch 56/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8329 - loss: 0.0330 - precision: 0.9529 - recall: 0.7508 - val_accuracy: 0.8315 - val_loss: 0.0370 - val_precision: 0.9432 - val_recall: 0.7562\n",
      "Epoch 57/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8353 - loss: 0.0321 - precision: 0.9607 - recall: 0.7479 - val_accuracy: 0.8417 - val_loss: 0.0379 - val_precision: 0.9477 - val_recall: 0.7709\n",
      "Epoch 58/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8492 - loss: 0.0323 - precision: 0.9609 - recall: 0.7694 - val_accuracy: 0.8340 - val_loss: 0.0354 - val_precision: 0.9551 - val_recall: 0.7504\n",
      "Epoch 59/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8417 - loss: 0.0321 - precision: 0.9633 - recall: 0.7576 - val_accuracy: 0.8623 - val_loss: 0.0382 - val_precision: 0.9348 - val_recall: 0.8209\n",
      "Epoch 60/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8383 - loss: 0.0318 - precision: 0.9602 - recall: 0.7520 - val_accuracy: 0.8392 - val_loss: 0.0359 - val_precision: 0.9506 - val_recall: 0.7636\n",
      "Epoch 61/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8379 - loss: 0.0319 - precision: 0.9651 - recall: 0.7507 - val_accuracy: 0.8563 - val_loss: 0.0405 - val_precision: 0.9430 - val_recall: 0.8018\n",
      "Epoch 62/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8439 - loss: 0.0319 - precision: 0.9539 - recall: 0.7667 - val_accuracy: 0.8400 - val_loss: 0.0368 - val_precision: 0.9491 - val_recall: 0.7665\n",
      "Epoch 63/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8465 - loss: 0.0317 - precision: 0.9617 - recall: 0.7661 - val_accuracy: 0.8272 - val_loss: 0.0354 - val_precision: 0.9493 - val_recall: 0.7430\n",
      "Epoch 64/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8500 - loss: 0.0314 - precision: 0.9680 - recall: 0.7677 - val_accuracy: 0.8460 - val_loss: 0.0365 - val_precision: 0.9434 - val_recall: 0.7827\n",
      "Epoch 65/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.8420 - loss: 0.0312 - precision: 0.9625 - recall: 0.7548 - val_accuracy: 0.8623 - val_loss: 0.0397 - val_precision: 0.9276 - val_recall: 0.8282\n",
      "Epoch 66/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8651 - loss: 0.0284 - precision: 0.9644 - recall: 0.8032 - val_accuracy: 0.8169 - val_loss: 0.0372 - val_precision: 0.9587 - val_recall: 0.7166\n",
      "Epoch 67/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8476 - loss: 0.0307 - precision: 0.9692 - recall: 0.7638 - val_accuracy: 0.8426 - val_loss: 0.0357 - val_precision: 0.9477 - val_recall: 0.7724\n",
      "Epoch 68/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8429 - loss: 0.0308 - precision: 0.9647 - recall: 0.7575 - val_accuracy: 0.8529 - val_loss: 0.0365 - val_precision: 0.9537 - val_recall: 0.7856\n",
      "Epoch 69/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8577 - loss: 0.0297 - precision: 0.9674 - recall: 0.7816 - val_accuracy: 0.8229 - val_loss: 0.0361 - val_precision: 0.9472 - val_recall: 0.7372\n",
      "Epoch 70/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8552 - loss: 0.0292 - precision: 0.9661 - recall: 0.7759 - val_accuracy: 0.8460 - val_loss: 0.0375 - val_precision: 0.9465 - val_recall: 0.7797\n",
      "Epoch 71/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8553 - loss: 0.0296 - precision: 0.9622 - recall: 0.7804 - val_accuracy: 0.8554 - val_loss: 0.0377 - val_precision: 0.9491 - val_recall: 0.7944\n",
      "Epoch 72/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8558 - loss: 0.0298 - precision: 0.9660 - recall: 0.7808 - val_accuracy: 0.8435 - val_loss: 0.0372 - val_precision: 0.9527 - val_recall: 0.7695\n",
      "Epoch 73/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8651 - loss: 0.0282 - precision: 0.9605 - recall: 0.8014 - val_accuracy: 0.8486 - val_loss: 0.0368 - val_precision: 0.9452 - val_recall: 0.7856\n",
      "Epoch 74/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8546 - loss: 0.0293 - precision: 0.9623 - recall: 0.7830 - val_accuracy: 0.8477 - val_loss: 0.0377 - val_precision: 0.9420 - val_recall: 0.7871\n",
      "Epoch 75/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8631 - loss: 0.0277 - precision: 0.9670 - recall: 0.7924 - val_accuracy: 0.8614 - val_loss: 0.0397 - val_precision: 0.9376 - val_recall: 0.8164\n",
      "Epoch 76/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8544 - loss: 0.0298 - precision: 0.9594 - recall: 0.7861 - val_accuracy: 0.8281 - val_loss: 0.0385 - val_precision: 0.9528 - val_recall: 0.7416\n",
      "Epoch 77/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8534 - loss: 0.0292 - precision: 0.9699 - recall: 0.7737 - val_accuracy: 0.8221 - val_loss: 0.0366 - val_precision: 0.9539 - val_recall: 0.7298\n",
      "Epoch 78/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8507 - loss: 0.0299 - precision: 0.9634 - recall: 0.7724 - val_accuracy: 0.8520 - val_loss: 0.0372 - val_precision: 0.9504 - val_recall: 0.7871\n",
      "Epoch 79/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8637 - loss: 0.0286 - precision: 0.9632 - recall: 0.7947 - val_accuracy: 0.8443 - val_loss: 0.0374 - val_precision: 0.9479 - val_recall: 0.7753\n",
      "Epoch 80/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8696 - loss: 0.0280 - precision: 0.9634 - recall: 0.8063 - val_accuracy: 0.8477 - val_loss: 0.0375 - val_precision: 0.9405 - val_recall: 0.7885\n",
      "Epoch 81/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8632 - loss: 0.0291 - precision: 0.9612 - recall: 0.7987 - val_accuracy: 0.8315 - val_loss: 0.0390 - val_precision: 0.9449 - val_recall: 0.7548\n",
      "Epoch 82/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8665 - loss: 0.0275 - precision: 0.9691 - recall: 0.7967 - val_accuracy: 0.8358 - val_loss: 0.0368 - val_precision: 0.9486 - val_recall: 0.7592\n",
      "Epoch 83/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8647 - loss: 0.0272 - precision: 0.9692 - recall: 0.7950 - val_accuracy: 0.8589 - val_loss: 0.0391 - val_precision: 0.9314 - val_recall: 0.8179\n",
      "Epoch 84/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8718 - loss: 0.0268 - precision: 0.9643 - recall: 0.8059 - val_accuracy: 0.8640 - val_loss: 0.0394 - val_precision: 0.9365 - val_recall: 0.8223\n",
      "Epoch 85/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8780 - loss: 0.0270 - precision: 0.9693 - recall: 0.8166 - val_accuracy: 0.8589 - val_loss: 0.0395 - val_precision: 0.9403 - val_recall: 0.8091\n",
      "Epoch 86/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8733 - loss: 0.0258 - precision: 0.9673 - recall: 0.8075 - val_accuracy: 0.8529 - val_loss: 0.0389 - val_precision: 0.9396 - val_recall: 0.7988\n",
      "Epoch 87/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8635 - loss: 0.0269 - precision: 0.9693 - recall: 0.7913 - val_accuracy: 0.8340 - val_loss: 0.0367 - val_precision: 0.9534 - val_recall: 0.7518\n",
      "Epoch 88/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8754 - loss: 0.0262 - precision: 0.9711 - recall: 0.8096 - val_accuracy: 0.8563 - val_loss: 0.0432 - val_precision: 0.9254 - val_recall: 0.8194\n",
      "Epoch 89/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8710 - loss: 0.0271 - precision: 0.9665 - recall: 0.8068 - val_accuracy: 0.8400 - val_loss: 0.0387 - val_precision: 0.9427 - val_recall: 0.7724\n",
      "Epoch 90/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8785 - loss: 0.0243 - precision: 0.9739 - recall: 0.8151 - val_accuracy: 0.8486 - val_loss: 0.0393 - val_precision: 0.9437 - val_recall: 0.7871\n",
      "Epoch 91/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8893 - loss: 0.0241 - precision: 0.9729 - recall: 0.8352 - val_accuracy: 0.8503 - val_loss: 0.0391 - val_precision: 0.9362 - val_recall: 0.7974\n",
      "Epoch 92/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8764 - loss: 0.0263 - precision: 0.9708 - recall: 0.8124 - val_accuracy: 0.8477 - val_loss: 0.0405 - val_precision: 0.9420 - val_recall: 0.7871\n",
      "Epoch 93/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8753 - loss: 0.0257 - precision: 0.9701 - recall: 0.8100 - val_accuracy: 0.8597 - val_loss: 0.0444 - val_precision: 0.9217 - val_recall: 0.8297\n",
      "Epoch 94/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8807 - loss: 0.0253 - precision: 0.9683 - recall: 0.8212 - val_accuracy: 0.8460 - val_loss: 0.0421 - val_precision: 0.9481 - val_recall: 0.7783\n",
      "Epoch 95/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8847 - loss: 0.0246 - precision: 0.9761 - recall: 0.8209 - val_accuracy: 0.8554 - val_loss: 0.0437 - val_precision: 0.9197 - val_recall: 0.8238\n",
      "Epoch 96/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8832 - loss: 0.0245 - precision: 0.9722 - recall: 0.8233 - val_accuracy: 0.8597 - val_loss: 0.0424 - val_precision: 0.9217 - val_recall: 0.8297\n",
      "Epoch 97/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8901 - loss: 0.0239 - precision: 0.9704 - recall: 0.8371 - val_accuracy: 0.8597 - val_loss: 0.0428 - val_precision: 0.9316 - val_recall: 0.8194\n",
      "Epoch 98/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8848 - loss: 0.0245 - precision: 0.9675 - recall: 0.8320 - val_accuracy: 0.8306 - val_loss: 0.0382 - val_precision: 0.9448 - val_recall: 0.7533\n",
      "Epoch 99/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8741 - loss: 0.0246 - precision: 0.9736 - recall: 0.8054 - val_accuracy: 0.8494 - val_loss: 0.0408 - val_precision: 0.9376 - val_recall: 0.7944\n",
      "Epoch 100/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8922 - loss: 0.0232 - precision: 0.9720 - recall: 0.8394 - val_accuracy: 0.8503 - val_loss: 0.0386 - val_precision: 0.9392 - val_recall: 0.7944\n",
      "Epoch 101/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8920 - loss: 0.0229 - precision: 0.9754 - recall: 0.8351 - val_accuracy: 0.8546 - val_loss: 0.0414 - val_precision: 0.9182 - val_recall: 0.8238\n",
      "Epoch 102/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8919 - loss: 0.0232 - precision: 0.9719 - recall: 0.8388 - val_accuracy: 0.8392 - val_loss: 0.0410 - val_precision: 0.9302 - val_recall: 0.7827\n",
      "Epoch 103/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8887 - loss: 0.0244 - precision: 0.9738 - recall: 0.8322 - val_accuracy: 0.8392 - val_loss: 0.0389 - val_precision: 0.9394 - val_recall: 0.7739\n",
      "Epoch 104/200\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8879 - loss: 0.0231 - precision: 0.9745 - recall: 0.8280 - val_accuracy: 0.8383 - val_loss: 0.0396 - val_precision: 0.9393 - val_recall: 0.7724\n",
      "Epoch 104: early stopping\n",
      "pre-BiLSTM finished training\n",
      "pre-BiLSTM saved to /kaggle/working/pre-BiLSTM.h5\n"
     ]
    }
   ],
   "source": [
    "# training the models\n",
    "history = {}\n",
    "for model_name, model in models.items():\n",
    "    print('-' * 50)\n",
    "    early_stopping_f1 = EarlyStoppingF1(patience=20, mode='max', restore_best_weights=True)\n",
    "    history[model_name] = model.fit(\n",
    "        train_data, train_labels, batch_size=264, epochs=200,\n",
    "        validation_data=(test_data, test_labels), callbacks=[early_stopping_f1], verbose=1\n",
    "    )\n",
    "    print(f'{model_name} finished training')\n",
    "    save_path = f'/kaggle/working/{model_name}.h5'\n",
    "    model.save(save_path)\n",
    "    print(f'{model_name} saved to {save_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T16:31:09.435263Z",
     "iopub.status.busy": "2025-05-11T16:31:09.435013Z",
     "iopub.status.idle": "2025-05-11T16:31:12.988230Z",
     "shell.execute_reply": "2025-05-11T16:31:12.987686Z",
     "shell.execute_reply.started": "2025-05-11T16:31:09.435244Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "CNN-BiLSTM finished predicting\n",
      "--------------------------------------------------\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "BiLSTM finished predicting\n",
      "--------------------------------------------------\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "pre-CNN-BiLSTM finished predicting\n",
      "--------------------------------------------------\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "pre-BiLSTM finished predicting\n"
     ]
    }
   ],
   "source": [
    "# predicting the test data\n",
    "pred = {}\n",
    "for model_name , model in models.items():\n",
    "    print('-'*50)\n",
    "    tmp = model.predict(test_data)\n",
    "    pred[model_name] = (tmp > 0.50).astype(np.int64)\n",
    "    print(f'{model_name} finished predicting')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T16:31:23.145113Z",
     "iopub.status.busy": "2025-05-11T16:31:23.144873Z",
     "iopub.status.idle": "2025-05-11T16:31:23.155746Z",
     "shell.execute_reply": "2025-05-11T16:31:23.155113Z",
     "shell.execute_reply.started": "2025-05-11T16:31:23.145095Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.84       488\n",
      "           1       0.89      0.88      0.89       681\n",
      "\n",
      "    accuracy                           0.87      1169\n",
      "   macro avg       0.86      0.87      0.86      1169\n",
      "weighted avg       0.87      0.87      0.87      1169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels , pred['CNN-BiLSTM']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T16:33:51.731293Z",
     "iopub.status.busy": "2025-05-11T16:33:51.730742Z",
     "iopub.status.idle": "2025-05-11T16:33:51.887103Z",
     "shell.execute_reply": "2025-05-11T16:33:51.886488Z",
     "shell.execute_reply.started": "2025-05-11T16:33:51.731271Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'CNN-BILSTM')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf = confusion_matrix(test_labels , pred['CNN-BiLSTM'])\n",
    "sns.heatmap(conf , annot = True , fmt = 'd' , cmap = 'Blues')\n",
    "plt.title('CNN-BILSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T16:31:24.992361Z",
     "iopub.status.busy": "2025-05-11T16:31:24.991795Z",
     "iopub.status.idle": "2025-05-11T16:31:25.002761Z",
     "shell.execute_reply": "2025-05-11T16:31:25.001947Z",
     "shell.execute_reply.started": "2025-05-11T16:31:24.992339Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.89      0.84       488\n",
      "           1       0.91      0.84      0.87       681\n",
      "\n",
      "    accuracy                           0.86      1169\n",
      "   macro avg       0.85      0.86      0.86      1169\n",
      "weighted avg       0.86      0.86      0.86      1169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels , pred['BiLSTM']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T16:33:54.769719Z",
     "iopub.status.busy": "2025-05-11T16:33:54.769448Z",
     "iopub.status.idle": "2025-05-11T16:33:54.930807Z",
     "shell.execute_reply": "2025-05-11T16:33:54.930061Z",
     "shell.execute_reply.started": "2025-05-11T16:33:54.769698Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'BILSTM')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf = confusion_matrix(test_labels , pred['BiLSTM'])\n",
    "sns.heatmap(conf , annot = True , fmt = 'd' , cmap = 'Blues')\n",
    "plt.title('BILSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T16:31:34.751589Z",
     "iopub.status.busy": "2025-05-11T16:31:34.751006Z",
     "iopub.status.idle": "2025-05-11T16:31:34.762572Z",
     "shell.execute_reply": "2025-05-11T16:31:34.761931Z",
     "shell.execute_reply.started": "2025-05-11T16:31:34.751565Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82       488\n",
      "           1       0.88      0.86      0.87       681\n",
      "\n",
      "    accuracy                           0.85      1169\n",
      "   macro avg       0.84      0.84      0.84      1169\n",
      "weighted avg       0.85      0.85      0.85      1169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels , pred['pre-CNN-BiLSTM']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T16:33:58.283767Z",
     "iopub.status.busy": "2025-05-11T16:33:58.283218Z",
     "iopub.status.idle": "2025-05-11T16:33:58.435849Z",
     "shell.execute_reply": "2025-05-11T16:33:58.435066Z",
     "shell.execute_reply.started": "2025-05-11T16:33:58.283743Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'pre-CNN-BiLSTM')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf = confusion_matrix(test_labels , pred['pre-CNN-BiLSTM'])\n",
    "sns.heatmap(conf , annot = True , fmt = 'd' , cmap = 'Blues')\n",
    "plt.title('pre-CNN-BiLSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T16:31:37.588009Z",
     "iopub.status.busy": "2025-05-11T16:31:37.587410Z",
     "iopub.status.idle": "2025-05-11T16:31:37.599449Z",
     "shell.execute_reply": "2025-05-11T16:31:37.598687Z",
     "shell.execute_reply.started": "2025-05-11T16:31:37.587981Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.92      0.85       488\n",
      "           1       0.94      0.82      0.88       681\n",
      "\n",
      "    accuracy                           0.86      1169\n",
      "   macro avg       0.86      0.87      0.86      1169\n",
      "weighted avg       0.87      0.86      0.86      1169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels , pred['pre-BiLSTM']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T16:34:01.684624Z",
     "iopub.status.busy": "2025-05-11T16:34:01.684051Z",
     "iopub.status.idle": "2025-05-11T16:34:01.836117Z",
     "shell.execute_reply": "2025-05-11T16:34:01.835561Z",
     "shell.execute_reply.started": "2025-05-11T16:34:01.684594Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'pre-BiLSTM')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf = confusion_matrix(test_labels , pred['pre-BiLSTM'])\n",
    "sns.heatmap(conf , annot = True , fmt = 'd' , cmap = 'Blues')\n",
    "plt.title('pre-BiLSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T16:38:24.146029Z",
     "iopub.status.busy": "2025-05-11T16:38:24.145410Z",
     "iopub.status.idle": "2025-05-11T16:38:24.162888Z",
     "shell.execute_reply": "2025-05-11T16:38:24.162160Z",
     "shell.execute_reply.started": "2025-05-11T16:38:24.146005Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "CNN-BiLSTM 0.88659793814433\n",
      "--------------------------------------------------\n",
      "BiLSTM 0.8739495798319329\n",
      "--------------------------------------------------\n",
      "pre-CNN-BiLSTM 0.8664688427299704\n",
      "--------------------------------------------------\n",
      "pre-BiLSTM 0.8756841282251759\n",
      "--------------------------------------------------\n",
      "Best model in terms of f1-score is CNN-BiLSTM with score of : 0.8866\n"
     ]
    }
   ],
   "source": [
    "best = -np.inf\n",
    "best_model = ''\n",
    "for model_name , model in models.items():\n",
    "    print('-'*50)\n",
    "    tmp = f1_score(test_labels , pred[model_name])\n",
    "    if tmp > best:\n",
    "        best = tmp\n",
    "        best_model = model_name\n",
    "    print(model_name,f1_score(test_labels , pred[model_name]))\n",
    "print('-' * 50)\n",
    "print(f'Best model in terms of f1-score is {best_model} with score of : {best:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-11T16:31:13.133018Z",
     "iopub.status.idle": "2025-05-11T16:31:13.133330Z",
     "shell.execute_reply": "2025-05-11T16:31:13.133176Z",
     "shell.execute_reply.started": "2025-05-11T16:31:13.133163Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the tokenizer\n",
    "with open('/kaggle/working/bi_tokenizer.pkl', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7370526,
     "sourceId": 11741026,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
